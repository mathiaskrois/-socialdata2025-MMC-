{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voted = [\"VoteWatch-EP-voting-data_2004-2022/~$EP6_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\"]\n",
    "rcv = [\"VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def process_ep_voting_data(rcv_files, voted_docs_files):\n",
    "    \"\"\"\n",
    "    Process European Parliament voting data from RCV files and Voted docs files.\n",
    "    \n",
    "    Parameters:\n",
    "    rcv_files (list): List of filenames for RCV files\n",
    "    voted_docs_files (list): List of filenames for Voted docs files\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Combined dataframe with all relevant data for analysis\n",
    "    \"\"\"\n",
    "    # Check if the lists have the same length\n",
    "    if len(rcv_files) != len(voted_docs_files):\n",
    "        raise ValueError(\"The lists of RCV files and Voted docs files must have the same length\")\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for i, (rcv_file, voted_doc_file) in enumerate(zip(rcv_files, voted_docs_files)):\n",
    "        print(f\"Processing files {i+1}/{len(rcv_files)}: {rcv_file} and {voted_doc_file}\")\n",
    "        \n",
    "        # Determine EP session based on filename\n",
    "        if \"EP6\" in rcv_file:\n",
    "            ep_session = \"EP6\"\n",
    "            rcv_data = pd.read_excel(rcv_file, header=1)\n",
    "        elif \"EP7\" in rcv_file:\n",
    "            ep_session = \"EP7\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP8\" in rcv_file:\n",
    "            ep_session = \"EP8\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP9\" in rcv_file:\n",
    "            ep_session = \"EP9\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        else:\n",
    "            ep_session = \"Unknown\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        \n",
    "        # Load Voted docs data\n",
    "        voted_docs = pd.read_excel(voted_doc_file)\n",
    "        \n",
    "        # Get vote columns (columns starting from the 11th column in RCV data as per codebook)\n",
    "        vote_columns = rcv_data.columns[10:]\n",
    "        \n",
    "        # Process the data session by session to handle different column naming conventions\n",
    "        if ep_session == \"EP6\":\n",
    "            # For EP6, columns are different\n",
    "            votes_df = process_votes_ep6(rcv_data, voted_docs, vote_columns)\n",
    "        else:\n",
    "            # For EP7, EP8, EP9\n",
    "            if 'EP8' in rcv_file:\n",
    "                votes_df = process_votes_ep789(rcv_data, voted_docs, vote_columns, ep_session = 'EP8')  \n",
    "            elif 'EP9' in rcv_file:\n",
    "                votes_df = process_votes_ep789(rcv_data, voted_docs, vote_columns, ep_session = 'EP9')  \n",
    "            else:  \n",
    "                votes_df = process_votes_ep789(rcv_data, voted_docs, vote_columns)\n",
    "        \n",
    "        # Add EP session information\n",
    "        votes_df['ep_session'] = ep_session\n",
    "        \n",
    "        # Append to the list of results\n",
    "        all_data.append(votes_df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Perform final cleaning\n",
    "    combined_df = clean_combined_data(combined_df)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def process_votes_ep6(rcv_data, voted_docs, vote_columns):\n",
    "    \"\"\"Process voting data for EP6 session\"\"\"\n",
    "    \n",
    "    # Create a dictionary to map vote IDs to vote information\n",
    "    vote_info = {}\n",
    "    for _, row in voted_docs.iterrows():\n",
    "        vote_id = row['euro_act_id']\n",
    "        vote_info[vote_id] = {\n",
    "            'date': row['date'],\n",
    "            'title': row['title'],\n",
    "            'procedure': row['procedure'],\n",
    "            'reading': row['reading'],\n",
    "            'voting_rule': row['rule'],\n",
    "            'rapporteur': row['raporteur'],\n",
    "            'policy_area': row['main_policy_name'],\n",
    "            'subject': row['subject'],\n",
    "            'final_vote': row['final_vote'],\n",
    "            'result': row['result_code'],\n",
    "            'yes_count': row['yes'],\n",
    "            'no_count': row['no'],\n",
    "            'abstain_count': row['abstain']\n",
    "        }\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each MEP's votes\n",
    "    for _, mep_row in rcv_data.iterrows():\n",
    "        country = mep_row['Country']\n",
    "        party = mep_row['Party']\n",
    "        epg = mep_row['EPG']\n",
    "        \n",
    "        # Process each vote for this MEP\n",
    "        for i, vote_col in enumerate(vote_columns):\n",
    "            vote_id = i + 1  # Vote IDs start from 1\n",
    "            \n",
    "            # Skip if the vote ID isn't in the vote_info dictionary\n",
    "            if vote_id not in vote_info:\n",
    "                continue\n",
    "                \n",
    "            # Get MEP's vote (1=for, 2=against, 3=abstention, etc.)\n",
    "            mep_vote_code = mep_row[vote_col]\n",
    "            \n",
    "            # Skip if MEP was not active for this vote\n",
    "            if mep_vote_code == 0:\n",
    "                continue\n",
    "                \n",
    "            # Get vote information\n",
    "            info = vote_info[vote_id]\n",
    "            \n",
    "            # Create a record\n",
    "            results.append({\n",
    "                'country': country,\n",
    "                'national_party': party,\n",
    "                'epg': epg,\n",
    "                'vote_id': vote_id,\n",
    "                'vote': mep_vote_code,\n",
    "                'date': info['date'],\n",
    "                'title': info['title'],\n",
    "                'procedure': info['procedure'],\n",
    "                'reading': info['reading'],\n",
    "                'voting_rule': info['voting_rule'],\n",
    "                'rapporteur': info['rapporteur'],\n",
    "                'policy_area': info['policy_area'],\n",
    "                'subject': info['subject'],\n",
    "                'final_vote': info['final_vote'],\n",
    "                'result': info['result'],\n",
    "                'yes_count': info['yes_count'],\n",
    "                'no_count': info['no_count'],\n",
    "                'abstain_count': info['abstain_count']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def process_votes_ep789(rcv_data, voted_docs, vote_columns, ep_session = None):\n",
    "    \"\"\"Process voting data for EP7, EP8, EP9 sessions\"\"\"\n",
    "\n",
    "    if ep_session == 'EP8':\n",
    "        policy_area = \"De/Policy area\"\n",
    "        final_vote = 'Final \\nvote?'\n",
    "        yes = 'Yeas'\n",
    "    elif ep_session == 'EP9':\n",
    "        policy_area = 'Policy area'\n",
    "        final_vote = 'Final vote?'\n",
    "        yes = 'Yes'\n",
    "    else:\n",
    "        policy_area = 'De'\n",
    "        final_vote = 'Final vote?'\n",
    "        yes = 'Yeas'\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a dictionary to map vote IDs to vote information\n",
    "    vote_info = {}\n",
    "    for _, row in voted_docs.iterrows():\n",
    "        vote_id = row['Vote ID']\n",
    "        vote_info[vote_id] = {\n",
    "            'date': row['Date'],\n",
    "            'title': row['Title'],\n",
    "            'procedure': row['Procedure'],\n",
    "            'reading': row['Leg/Non-Leg/Bud'],\n",
    "            'voting_rule': row['Voting Rule'],\n",
    "            'rapporteur': row['Rapporteur'],\n",
    "            'policy_area': row[policy_area],  # Main policy area\n",
    "            'subject': row['Subject'],\n",
    "            'final_vote': row[final_vote],\n",
    "            'result': row['Vote'],\n",
    "            'yes_count': row[yes],\n",
    "            'no_count': row['No'],\n",
    "            'abstain_count': row['Abs']\n",
    "        }\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each MEP's votes\n",
    "    for _, mep_row in rcv_data.iterrows():\n",
    "        country = mep_row['Country']\n",
    "        party = mep_row['Party']\n",
    "        epg = mep_row['EPG']\n",
    "        \n",
    "        # Process each vote for this MEP\n",
    "        for i, vote_col in enumerate(vote_columns):\n",
    "            vote_id = i + 1  # Vote IDs start from 1\n",
    "            \n",
    "            # Skip if the vote ID isn't in the vote_info dictionary\n",
    "            if vote_id not in vote_info:\n",
    "                continue\n",
    "                \n",
    "            # Get MEP's vote (1=for, 2=against, 3=abstention, etc.)\n",
    "            mep_vote_code = mep_row[vote_col]\n",
    "            \n",
    "            # Skip if MEP was not active for this vote\n",
    "            if mep_vote_code == 0:\n",
    "                continue\n",
    "                \n",
    "            # Get vote information\n",
    "            info = vote_info[vote_id]\n",
    "            \n",
    "            # Create a record\n",
    "            results.append({\n",
    "                'country': country,\n",
    "                'national_party': party,\n",
    "                'epg': epg,\n",
    "                'vote_id': vote_id,\n",
    "                'vote': mep_vote_code,\n",
    "                'date': info['date'],\n",
    "                'title': info['title'],\n",
    "                'procedure': info['procedure'],\n",
    "                'reading': info['reading'],\n",
    "                'voting_rule': info['voting_rule'],\n",
    "                'rapporteur': info['rapporteur'],\n",
    "                'policy_area': info['policy_area'],\n",
    "                'subject': info['subject'],\n",
    "                'final_vote': info['final_vote'],\n",
    "                'result': info['result'],\n",
    "                'yes_count': info['yes_count'],\n",
    "                'no_count': info['no_count'],\n",
    "                'abstain_count': info['abstain_count']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def clean_combined_data(df):\n",
    "    \"\"\"Perform final cleaning and transformations on the combined dataframe\"\"\"\n",
    "    \n",
    "    # Convert date strings to datetime objects\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    \n",
    "    # Create a year column for easier filtering\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Create a month column for time-based analysis\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    # Convert numeric columns to appropriate types\n",
    "    for col in ['yes_count', 'no_count', 'abstain_count']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Create a binary vote column for easier analysis\n",
    "    df['vote_binary'] = df['vote'].map({\n",
    "        'for': 1,\n",
    "        'against': -1,\n",
    "        'abstention': 0,\n",
    "        'absent': np.nan,\n",
    "        'did not vote': np.nan,\n",
    "        'motivated absence': np.nan,\n",
    "        'not an MEP': np.nan,\n",
    "        'unknown': np.nan\n",
    "    })\n",
    "    \n",
    "    # Create a column for vote result (pass/fail)\n",
    "    df['vote_passed'] = df['result'].apply(lambda x: 1 if x == '+' else 0 if x == '-' else np.nan)\n",
    "    \n",
    "    # Clean up policy areas (standardize names)\n",
    "    df['policy_area'] = df['policy_area'].str.strip().str.lower()\n",
    "    \n",
    "    # Create a simplified procedure column\n",
    "    df['procedure_type'] = df['procedure'].apply(simplify_procedure)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def simplify_procedure(procedure_code):\n",
    "    \"\"\"Simplify procedure codes into broader categories\"\"\"\n",
    "    legislative_procedures = ['COD', 'CNS', 'APP', 'AVC', 'SYN', 'INL']\n",
    "    budget_procedures = ['BUD', 'BUI', 'DEC']\n",
    "    \n",
    "    if procedure_code in legislative_procedures:\n",
    "        return 'legislative'\n",
    "    elif procedure_code in budget_procedures:\n",
    "        return 'budgetary'\n",
    "    else:\n",
    "        return 'non-legislative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files 1/1: VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx and VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markusswegmark/Desktop/Visualization/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/var/folders/1h/fbz069916kvd8trkfrmhx0fr0000gn/T/ipykernel_18865/232753851.py:244: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to ep_voting_data_combined.csv\n",
      "DataFrame shape: (9520348, 24)\n",
      "\n",
      "Sample of the data:\n",
      "  country national_party  epg  vote_id  vote       date  \\\n",
      "0  Poland    Independent  EPP        1     5 2019-07-15   \n",
      "1  Poland    Independent  EPP        2     2 2019-07-18   \n",
      "2  Poland    Independent  EPP        3     1 2019-07-18   \n",
      "3  Poland    Independent  EPP        4     2 2019-07-18   \n",
      "4  Poland    Independent  EPP        5     2 2019-07-18   \n",
      "\n",
      "                                    title procedure reading voting_rule  ...  \\\n",
      "0  Tuesday - request by the GUE/NGL group       NaN     Non           s  ...   \n",
      "1     Situation at the USA-Mexican border       NaN     Non           s  ...   \n",
      "2     Situation at the USA-Mexican border       NaN     Non           s  ...   \n",
      "3     Situation at the USA-Mexican border       NaN     Non           s  ...   \n",
      "4     Situation at the USA-Mexican border       NaN     Non           s  ...   \n",
      "\n",
      "  result yes_count no_count  abstain_count ep_session  year  month  \\\n",
      "0      -        83      142             72        EP9  2019      7   \n",
      "1      +       311      269             33        EP9  2019      7   \n",
      "2      +       437      155             33        EP9  2019      7   \n",
      "3      +       441      158             27        EP9  2019      7   \n",
      "4      +       466      146             41        EP9  2019      7   \n",
      "\n",
      "   vote_binary vote_passed   procedure_type  \n",
      "0          NaN           0  non-legislative  \n",
      "1          NaN           1  non-legislative  \n",
      "2          NaN           1  non-legislative  \n",
      "3          NaN           1  non-legislative  \n",
      "4          NaN           1  non-legislative  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mep_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Visualization/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'mep_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Print some basic statistics\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBasic statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of unique MEPs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmep_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of unique votes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m'\u001b[39m\u001b[33mvote_id\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Visualization/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Visualization/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'mep_name'"
     ]
    }
   ],
   "source": [
    "\n",
    "voted_docs_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\"]\n",
    "rcv_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx\"]\n",
    "\n",
    "# Process the data\n",
    "combined_df = process_ep_voting_data(rcv_files, voted_docs_files)\n",
    "\n",
    "# Save the combined dataframe\n",
    "output_file = \"ep_voting_data_combined.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined data saved to {output_file}\")\n",
    "print(f\"DataFrame shape: {combined_df.shape}\")\n",
    "print(\"\\nSample of the data:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Print some basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(f\"Number of unique votes: {combined_df['vote_id'].nunique()}\")\n",
    "print(f\"Date range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n",
    "print(f\"Number of parliamentary groups: {combined_df['epg'].nunique()}\")\n",
    "print(f\"Number of countries: {combined_df['country'].nunique()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
