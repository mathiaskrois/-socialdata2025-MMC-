{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Motivation\n",
    "\n",
    "### What is your dataset?\n",
    "\n",
    "We selected a comprehensive dataset of European Parliament voting records. This dataset captures how each Member of the European Parliament (MEP) voted on proposed legislation, along with detailed information about the legislation itself, the MEPs, and their party affiliations. The dataset includes two main file types:\n",
    "\n",
    "* **RCV (Roll Call Votes):** Contains individual vote records for each MEP, including their country, national party, and European Parliamentary Group (EPG).\n",
    "* **Voted Docs:** Provides metadata on the legislation being voted on, including the vote date, outcome, and associated policy area.\n",
    "\n",
    "The data is divided across four parliamentary sessions:\n",
    "\n",
    "* EP6 (2004‚Äì2009)\n",
    "* EP7 (2009‚Äì2014)\n",
    "* EP8 (2014‚Äì2019)\n",
    "* EP9 (2019‚Äì2022)\n",
    "\n",
    "To enable longitudinal analysis, we merged data from all four sessions. This required extensive preprocessing to reconcile differences in schema and formatting across sessions.\n",
    "\n",
    "### Why did you choose this particular dataset?\n",
    "\n",
    "We chose this dataset because it offers a rich foundation for analyzing trends in European politics over time. It enables us to explore whether broader political shifts‚Äîsuch as increasing polarization or the rise of right-leaning ideologies‚Äîare observable in parliamentary voting behavior.\n",
    "\n",
    "### What was your goal for the end user's experience?\n",
    "\n",
    "Our goal is to provide users with an accessible interface to explore aggregated voting patterns and to present clear, data-driven insights into evolving political dynamics within the European Parliament. We aim to make it easy for users to identify trends related to polarization, such as which parties or policy areas are becoming more divisive, and which remain broadly supported. Ultimately, we want to support informed reflection on how shifts in ideology are shaping legislative decision-making at the EU level.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Basic Stats\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "To analyze voting trends in the European Parliament across four sessions (EP6‚ÄìEP9), we consolidated roll-call vote data (`RCV`) with metadata on each legislative item (`Voted Docs`). Due to inconsistencies across sessions in schema, date formats, and naming conventions, several preprocessing steps were necessary:\n",
    "\n",
    "* **Name Standardization:** MEP names were cleaned to ensure consistency across sessions, accounting for formatting, punctuation, and Unicode differences.\n",
    "* **Text Normalization:** Policy area fields and party/EPG names were cleaned to remove noise (e.g., punctuation, inconsistent capitalization).\n",
    "* **Date Parsing:** Dates appeared in both `dd.mm.yyyy` and `yyyy-mm-dd` formats. A custom parser ensured accurate conversion to a uniform `datetime` format.\n",
    "* **Schema Harmonization:** Since column names and vote identifiers varied by session (e.g., `euro_act_id` in EP6 vs `Vote ID` in later sessions), we created session-aware mappings to unify data.\n",
    "* **Party Group Mapping:** EP political group (`EPG`) names were mapped to their common abbreviations (e.g., ‚ÄúGroup of the European People‚Äôs Party...‚Äù ‚Üí `EPP`) to allow for consistent comparison.\n",
    "* **Missing Values:** Non-informative entries (e.g., empty vote fields or unknown policy areas) were filtered or imputed based on context.\n",
    "\n",
    "These steps allowed us to generate a unified dataset spanning 2004‚Äì2022 with over **4.8 million individual votes**.\n",
    "\n",
    "### Dataset Statistics\n",
    "\n",
    "Key observations from the cleaned data:\n",
    "\n",
    "* üìÖ **Time Coverage:** The dataset spans four European Parliament terms:\n",
    "\n",
    "  * EP6: 2004‚Äì2009\n",
    "  * EP7: 2009‚Äì2014\n",
    "  * EP8: 2014‚Äì2019\n",
    "  * EP9: 2019‚Äì2022\n",
    "\n",
    "* üßë‚Äçü§ù‚Äçüßë **MEPs Involved:** \\~1,300 unique MEPs from all 27 EU member states.\n",
    "\n",
    "* üìÑ **Votes Recorded:**\n",
    "\n",
    "  * \\~26,000 roll-call votes\n",
    "  * \\~4.8 million MEP-level voting entries (rows)\n",
    "\n",
    "* üó≥Ô∏è **Vote Distribution (Sample):**\n",
    "\n",
    "  | Vote      | Meaning                    | % of Total     |\n",
    "  | --------- | -------------------------- | -------------- |\n",
    "  | 1         | For                        | \\~48%          |\n",
    "  | 2         | Against                    | \\~27%          |\n",
    "  | 3         | Abstain                    | \\~12%          |\n",
    "  | 4 / 5 / 6 | Absent / No vote / Excused | \\~13% combined |\n",
    "\n",
    "* üèõÔ∏è **Top Policy Areas:** After cleaning and consolidating, common topics included:\n",
    "\n",
    "  * Environment\n",
    "  * Budget and financial affairs\n",
    "  * Foreign relations\n",
    "  * Digital and industry regulation\n",
    "  * Civil rights and rule of law\n",
    "\n",
    "* üß≠ **EP Group Participation:** Most votes came from major groups like `EPP`, `S&D`, `Renew`, `ID`, `Greens/EFA`, and `The Left`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_name(first_name, last_name):\n",
    "    import unicodedata\n",
    "    \n",
    "    if not isinstance(first_name, str):\n",
    "        first_name = str(first_name) if first_name is not None else \"\"\n",
    "    if not isinstance(last_name, str):\n",
    "        last_name = str(last_name) if last_name is not None else \"\"\n",
    "    \n",
    "    first_name = first_name.lower().strip()\n",
    "    last_name = last_name.lower().strip()\n",
    "    \n",
    "    def normalize_chars(text):\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        return text\n",
    "    \n",
    "    first_name = normalize_chars(first_name)\n",
    "    last_name = normalize_chars(last_name)\n",
    "    \n",
    "    for char in ['-', \"'\", \"`\", \".\", \",\", \"&\", \"'\"]:  # Added apostrophe variants\n",
    "        first_name = first_name.replace(char, ' ')\n",
    "        last_name = last_name.replace(char, ' ')\n",
    "    \n",
    "    while '  ' in first_name:\n",
    "        first_name = first_name.replace('  ', ' ')\n",
    "    while '  ' in last_name:\n",
    "        last_name = last_name.replace('  ', ' ')\n",
    "        \n",
    "    first_name = ' '.join(word.capitalize() for word in first_name.split())\n",
    "    last_name = ' '.join(word.capitalize() for word in last_name.split())\n",
    "    \n",
    "    full_name = f\"{first_name} {last_name}\".strip()\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "  \n",
    "    text = text.lower()\n",
    "    \n",
    "    for char in ['&', ',', '-']:\n",
    "        text = text.replace(char, ' ')\n",
    "    \n",
    "    text = text.replace(' and ', ' ')\n",
    "    \n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    \n",
    "    return text.strip()    \n",
    "\n",
    "def process_ep_voting_data(rcv_files, voted_docs_files):\n",
    "\n",
    "    if len(rcv_files) != len(voted_docs_files):\n",
    "        raise ValueError(\"The lists of RCV files and Voted docs files must have the same length\")\n",
    "     \n",
    "    all_data = []\n",
    "    \n",
    "    for i, (rcv_file, voted_doc_file) in enumerate(zip(rcv_files, voted_docs_files)):\n",
    "        print(f\"Processing files {i+1}/{len(rcv_files)}: {rcv_file} and {voted_doc_file}\")\n",
    "        \n",
    "        if \"EP6\" in rcv_file:\n",
    "            ep_session = \"EP6\"\n",
    "            vote_start_index = 10\n",
    "            rcv_data = pd.read_excel(rcv_file, header=1)\n",
    "        elif \"EP7\" in rcv_file:\n",
    "            ep_session = \"EP7\"\n",
    "            vote_start_index = 9\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP8\" in rcv_file:\n",
    "            ep_session = \"EP8\"\n",
    "            vote_start_index = 9\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP9\" in rcv_file:\n",
    "            ep_session = \"EP9\"\n",
    "            vote_start_index = 10\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        else:\n",
    "            ep_session = \"Unknown\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "            print(\"UNKNOWN SESSION\")\n",
    "\n",
    "        rcv_data = rcv_data.dropna(how='all')\n",
    "        \n",
    "        voted_docs = pd.read_excel(voted_doc_file)\n",
    "\n",
    "\n",
    "        # Get vote columns headers (index)\n",
    "        vote_columns = rcv_data.columns[vote_start_index:].tolist()\n",
    "       \n",
    "        votes_df = process_votes_ep(rcv_data, voted_docs, vote_columns, ep_session=ep_session)\n",
    "\n",
    "        print(f\"Should be around: {len(rcv_data) * len(voted_docs)}\")\n",
    "        print(f\"Got: {len(votes_df)}\")      \n",
    "\n",
    "        # Add EP session information\n",
    "        votes_df['ep_session'] = ep_session\n",
    "        \n",
    "        # Append to the list of results\n",
    "        all_data.append(votes_df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Perform final cleaning\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def process_votes_ep(rcv_data, voted_docs, vote_columns, ep_session = None):\n",
    "    \"\"\"Process voting data for EP7, EP8, EP9 sessions\"\"\"\n",
    "\n",
    "    total_skipped = 0\n",
    "\n",
    "    if ep_session == 'EP6':\n",
    "        date = 'date'\n",
    "        title = 'title'\n",
    "        policy_area = 'main_policy_name'\n",
    "        vote_id_key = 'euro_act_id'\n",
    "        author = 'author_name'\n",
    "\n",
    "        mep_id_key = 'WebisteEpID'\n",
    "\n",
    "    else:\n",
    "        date = 'Date'\n",
    "        title = 'Title'\n",
    "        policy_area = 'De'\n",
    "        vote_id_key = 'Vote ID'\n",
    "        author = 'Author'\n",
    "\n",
    "        mep_id_key = 'WebisteEpID'\n",
    "\n",
    "        if ep_session == 'EP7':\n",
    "            mep_id_key = 'MEP ID'\n",
    "\n",
    "        if ep_session == 'EP8':\n",
    "            policy_area = \"De/Policy area\"\n",
    "\n",
    "        elif ep_session == 'EP9':\n",
    "            policy_area = 'Policy area'\n",
    "  \n",
    "    \n",
    "    # Create a dictionary to map vote IDs to vote information\n",
    "    vote_info = {}\n",
    "    for _, row in voted_docs.iterrows():\n",
    "\n",
    "        vote_info[str(row[vote_id_key])] = {\n",
    "            'date': row[date],\n",
    "            'title': row[title],\n",
    "            'policy_area': row[policy_area],\n",
    "            'author': author,\n",
    "        }\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each MEP's votes\n",
    "    for _, mep_row in rcv_data.iterrows():\n",
    "        country = mep_row['Country']\n",
    "        party = mep_row['Party']\n",
    "        epg = mep_row['EPG']\n",
    "\n",
    "        first_name = mep_row['Fname']\n",
    "        last_name = mep_row['Lname']\n",
    "        \n",
    "        mep_id = mep_row[mep_id_key]\n",
    "    \n",
    "        # Process each vote for this MEP\n",
    "        for vote_col in vote_columns:\n",
    "            \n",
    "            vote_col = str(vote_col)\n",
    "            vote_code = f'{ep_session}-{vote_col}' \n",
    "            \n",
    "            if vote_col not in vote_info:\n",
    "                total_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                mep_vote = mep_row[str(vote_col)]\n",
    "            except Exception as e:\n",
    "                mep_vote = mep_row[int(vote_col)]\n",
    "            \n",
    "            if mep_vote == 0:\n",
    "                continue\n",
    "                \n",
    "            info = vote_info[vote_col]\n",
    "            \n",
    "            results.append({\n",
    "                'full name': clean_name(first_name, last_name),\n",
    "                'country': country,\n",
    "                'national_party': party,\n",
    "                'epg': epg,\n",
    "                'mep_id': mep_id,\n",
    "                'vote_code': vote_code,\n",
    "                'vote': mep_vote,\n",
    "                'date': info['date'],\n",
    "                'title': info['title'],\n",
    "                'policy_area': clean_text(info['policy_area']),\n",
    "            })\n",
    "    \n",
    "    print(f\"Were not able to match: {total_skipped} votes\")\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_mixed_dates(date_str):\n",
    "    \n",
    "    if not isinstance(date_str, str):\n",
    "        date_str = str(date_str)\n",
    "    \n",
    "    date_str = date_str.strip()\n",
    "    \n",
    "    try:\n",
    "        # Check for dates with time component\n",
    "        if \" 00:00:00\" in date_str:\n",
    "            date_str = date_str.replace(\" 00:00:00\", \"\")\n",
    "\n",
    "        if date_str == '18 ian 2007':\n",
    "            return pd.to_datetime('2007-01-18')\n",
    "        \n",
    "        if '.' in date_str:\n",
    "            # Parse as dd.mm.yyyy\n",
    "            return pd.to_datetime(date_str, format='%d.%m.%Y')\n",
    "        elif '-' in date_str:\n",
    "            # Parse as yyyy-mm-dd\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        elif '/' in date_str:\n",
    "            try:\n",
    "                # First try %d/%m/%Y (day/month/4-digit year)\n",
    "                return pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    # Then try %d/%m/%y (day/month/2-digit year)\n",
    "                    return pd.to_datetime(date_str, format='%d/%m/%y')\n",
    "                except ValueError:\n",
    "                    # Fall back to pandas default parser with dayfirst=True\n",
    "                    return pd.to_datetime(date_str, dayfirst=True)\n",
    "        else:\n",
    "            # For formats we haven't explicitly handled, use pandas' flexible parser\n",
    "            return pd.to_datetime(date_str)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date '{date_str}': {e}\")\n",
    "        return pd.NaT  # In case of error\n",
    "    \n",
    "\n",
    "def clean_combined_data(df):\n",
    "    \n",
    "    df['date'] = df['date'].astype(str).apply(parse_mixed_dates)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    df['policy_area_cleaned'] = df['policy_area'].str.strip().str.lower()\n",
    "\n",
    "    # Map EPG to ture names:\n",
    "    epg_mapping = {\n",
    "        \"Group of the European People's Party (Christian Democrats)\": 'EPP',\n",
    "        \"Group of the European People's Party (Christian Democrats) and European Democrats\": 'EPP',\n",
    "        'Socialist Group in the European Parliament': 'S&D',\n",
    "        'Group of the Progressive Alliance of Socialists and Democrats in the European Parliament': 'S&D',\n",
    "        'Confederal Group of the European United Left - Nordic Green Left': 'The Left',\n",
    "        'Group of the Greens/European Free Alliance': 'Greens/EFA',\n",
    "        'Independence/Democracy Group': 'IDG',\n",
    "        'Europe of freedom and democracy Group': 'IDG',\n",
    "        'Europe of Freedom and Direct Democracy Group': 'IDG',\n",
    "        'Europe of Nations and Freedom Group': 'ID',\n",
    "        'European Conservatives and Reformists Group': 'ECR',\n",
    "        'Non-attached Members': 'NI',\n",
    "        'Group of the Alliance of Liberals and Democrats for Europe' : 'REG'\n",
    "    }\n",
    "    df['epg'] = df['epg'].replace(epg_mapping)\n",
    "\n",
    "    # Merge PA \n",
    "    df['policy_area'] = df['policy_area'].replace('regioanal development', 'regional development')\n",
    "    df['policy_area'] = df['policy_area'].replace('economic monetary affairs', 'economics')\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files 1/4: VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx and VoteWatch-EP-voting-data_2004-2022/EP6_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be around: 5827060\n",
      "Got: 4759840\n",
      "Processing files 2/4: VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx and VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be around: 5937733\n",
      "Got: 5233859\n",
      "Processing files 3/4: VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx and VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be around: 8796216\n",
      "Got: 7696506\n",
      "Processing files 4/4: VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx and VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markusswegmark/dev/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Were not able to match: 0 votes\n",
      "Should be around: 10915249\n",
      "Got: 9520348\n",
      "Saving uncleaned data\n",
      "Cleaning data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "voted_docs_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\"]\n",
    "rcv_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx\"]\n",
    "\n",
    "df = process_ep_voting_data(rcv_files, voted_docs_files)\n",
    "\n",
    "print('Saving uncleaned data')\n",
    "\n",
    "# Save the combined dataframe\n",
    "output_file = \"ep_voting_data_combined_raw.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print('Cleaning data')\n",
    "df = clean_combined_data(df)\n",
    "\n",
    "print('Saving cleaned data')\n",
    "\n",
    "output_file = \"ep_voting_data_combined_clean.csv\"\n",
    "df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers:\n",
      "['full name', 'country', 'national_party', 'epg', 'mep_id', 'vote_code', 'vote', 'date', 'title', 'policy_area', 'ep_session', 'year', 'month', 'policy_area_cleaned']\n"
     ]
    }
   ],
   "source": [
    "# Get all column headers as a list\n",
    "headers_list = df.columns.tolist()\n",
    "print(\"Column headers:\")\n",
    "print(headers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    df = pd.read_csv('ep_voting_data_combined_clean.csv', dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_52017/818729727.py:35: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = clean_combined_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full name', 'country', 'national_party', 'epg', 'mep_id', 'vote_code', 'vote', 'date', 'title', 'policy_area', 'ep_session', 'year', 'month', 'policy_area_cleaned']\n"
     ]
    }
   ],
   "source": [
    "headers_list = list(df.columns)\n",
    "print(headers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'EPP'}, {'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'EPP'}, {'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'EPP'}, {'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'EPP'}, {'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'EPP'}, {'NI', 'Union for Europe of the Nations Group', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'The Left', 'S&D', 'IDG', 'Greens/EFA', 'REG', 'ID', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}, {'NI', 'S&D', 'The Left', 'IDG', 'Greens/EFA', 'REG', 'ECR', 'EPP'}]\n",
      "EPGs present in all 19 years:\n",
      "['EPP', 'Greens/EFA', 'IDG', 'NI', 'REG', 'S&D', 'The Left']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Find EPGs present in all years\n",
    "years = df['year'].unique()\n",
    "epgs_by_year = [set(df[df['year'] == year]['epg'].dropna().unique()) for year in years]\n",
    "\n",
    "print(epgs_by_year)\n",
    "# Step 2: Find common EPGs\n",
    "common_epgs = set.intersection(*epgs_by_year)\n",
    "\n",
    "# Step 3: Print the result\n",
    "print(f\"EPGs present in all {len(years)} years:\")\n",
    "print(sorted(common_epgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simmilarity matrix between EPGs for each year and policy area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall: 0/8106 EPG pairs have missing vote data (0.0%)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def agreement_index(votes1, votes2):\n",
    "    \"\"\"\n",
    "    Calculate agreement between two voting groups based on vote percentage distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - votes1, votes2: Series of vote counts indexed by vote type (1=for, 2=against, 3=abstention, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    - Similarity score between 0 and 1, based on overlap of percentage distributions\n",
    "    \"\"\"\n",
    "    # Calculate total votes for each group\n",
    "    total_votes_1 = sum(votes1)\n",
    "    total_votes_2 = sum(votes2)\n",
    "    \n",
    "    total_agreement = 0\n",
    "    \n",
    "    # For each vote type, calculate the proportion of agreement based on percentages\n",
    "    for i in range(len(votes1)):\n",
    "        # Calculate percentages\n",
    "        pct1 = votes1[i] / total_votes_1\n",
    "        pct2 = votes2[i] / total_votes_2\n",
    "        \n",
    "        # Add minimum percentage as the agreement for this vote type\n",
    "        total_agreement += min(pct1, pct2)\n",
    "    \n",
    "    # The sum of all minimum percentages directly represents the overlap\n",
    "    # between the two distributions (ranges from 0 to 1)\n",
    "    return total_agreement\n",
    "\n",
    "# Modified code to use the new similarity function\n",
    "df['epg'] = df['epg'].astype(str)\n",
    "df['year'] = df['year'].astype(float).astype(int)\n",
    "df_year = df.groupby(['year', 'policy_area'])\n",
    "epgs = sorted(list(common_epgs))\n",
    "similarity_matrices = {}\n",
    "\n",
    "# Track missing data\n",
    "missing_data_count = 0\n",
    "total_combinations = 0\n",
    "\n",
    "for name, group in df_year:\n",
    "    year, policy_area = name \n",
    "    year = int(year)\n",
    "    sim_matrix = pd.DataFrame(index=epgs, columns=epgs)\n",
    "    \n",
    "    # Track missing data for this year/policy_area\n",
    "    missing_in_current = 0\n",
    "    total_in_current = 0\n",
    "    \n",
    "    # Calculate similarities between all EPG pairs\n",
    "    for epg1, epg2 in combinations(epgs, 2):\n",
    "        total_combinations += 1\n",
    "        total_in_current += 1\n",
    "        \n",
    "        ep1_votes_series = group[group['epg'] == epg1]['vote'].value_counts()\n",
    "        ep2_votes_series = group[group['epg'] == epg2]['vote'].value_counts()\n",
    "\n",
    "        # Initialize arrays with zeros for vote types 1, 2, and 3\n",
    "        ep1_votes = [0, 0, 0]  # Index 0 for vote value 1, index 1 for vote value 2, etc.\n",
    "        ep2_votes = [0, 0, 0]\n",
    "\n",
    "        # Fill in the counts from the Series, handling both int and float vote types\n",
    "        for vote_type, count in ep1_votes_series.items():\n",
    "            vote_index = int(float(vote_type)) - 1  # Convert vote type (1,2,3) to index (0,1,2)\n",
    "            if 0 <= vote_index <= 2:  # Only include vote types 1, 2, and 3\n",
    "                ep1_votes[vote_index] = count\n",
    "\n",
    "        for vote_type, count in ep2_votes_series.items():\n",
    "            vote_index = int(float(vote_type)) - 1\n",
    "            if 0 <= vote_index <= 2:\n",
    "                ep2_votes[vote_index] = count\n",
    "\n",
    "        \n",
    "        # Check if any relevant votes exist for both EPGs\n",
    "        has_votes_1 = sum(ep1_votes) != 0\n",
    "        has_votes_2 = sum(ep2_votes) != 0\n",
    "        \n",
    "        if not has_votes_1 or not has_votes_2:\n",
    "            missing_data_count += 1\n",
    "            missing_in_current += 1\n",
    "            similarity = 0  # No relevant votes, similarity is 0\n",
    "        else:\n",
    "            similarity = agreement_index(ep1_votes, ep2_votes)\n",
    "            \n",
    "        sim_matrix.loc[epg1, epg2] = similarity\n",
    "        sim_matrix.loc[epg2, epg1] = similarity  # Matrix is symmetric\n",
    "    \n",
    "    # Set diagonal to 1 (self-similarity)\n",
    "    for epg in epgs:\n",
    "        sim_matrix.loc[epg, epg] = 1.0\n",
    "            \n",
    "    # Store the matrix\n",
    "    if policy_area not in similarity_matrices:\n",
    "        similarity_matrices[policy_area] = {}\n",
    "    similarity_matrices[policy_area][year] = sim_matrix\n",
    "    \n",
    "    # Print summary for this year/policy_area\n",
    "    if missing_in_current > 0:\n",
    "        print(f\"Year {year}, Policy Area '{policy_area}': {missing_in_current}/{total_in_current} EPG pairs have missing vote data ({missing_in_current/total_in_current:.1%})\")\n",
    "\n",
    "# Print overall summary\n",
    "print(f\"\\nOverall: {missing_data_count}/{total_combinations} EPG pairs have missing vote data ({missing_data_count/total_combinations:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PCA, tranform with procrustes and animate over time for paramter policy area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to 'epg_clustering_animation_better_zoom.html'. Open this file in a web browser to view the animation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from bokeh.plotting import figure, save, output_file\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Slider, CustomJS, Button, Range1d\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "# Set output to an HTML file\n",
    "output_file(\"epg_clustering_animation_better_zoom.html\")\n",
    "\n",
    "# Select a single policy area to visualize\n",
    "policy_area = 'budget'  # Change this to any policy area you want\n",
    "\n",
    "# Get all available years for this policy area\n",
    "years = sorted(similarity_matrices[policy_area].keys())\n",
    "\n",
    "# Get EPGs from the first year\n",
    "epgs = list(similarity_matrices[policy_area][years[0]].index)\n",
    "\n",
    "# Create color mapping for EPGs\n",
    "epg_colors = {}\n",
    "palette = Category10[10]\n",
    "for i, epg in enumerate(epgs):\n",
    "    epg_colors[epg] = palette[i % len(palette)]\n",
    "\n",
    "# Function to perform dimensionality reduction on a similarity matrix\n",
    "def get_coordinates(similarity_matrix, method='pca'):\n",
    "    # Convert similarity to distance matrix\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    X = distance_matrix.values\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    if method == 'pca':\n",
    "        model = PCA(n_components=2)\n",
    "        result = model.fit_transform(X)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    df_result = pd.DataFrame({\n",
    "        'x': result[:, 0],\n",
    "        'y': result[:, 1],\n",
    "        'epg': distance_matrix.index,\n",
    "        'color': [epg_colors.get(epg, '#000000') for epg in distance_matrix.index]\n",
    "    })\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Function to align coordinates with reference using Procrustes analysis\n",
    "def align_coordinates(target_df, reference_df):\n",
    "    # Get common EPGs\n",
    "    common_epgs = set(target_df['epg']).intersection(set(reference_df['epg']))\n",
    "    \n",
    "    if len(common_epgs) < 2:\n",
    "        # Not enough common points to align\n",
    "        return target_df\n",
    "    \n",
    "    # Extract coordinates for common EPGs\n",
    "    target_coords = np.array([target_df[target_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "    reference_coords = np.array([reference_df[reference_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "    \n",
    "    # Perform Procrustes analysis to align target to reference\n",
    "    mtx1, mtx2, disparity = procrustes(reference_coords, target_coords)\n",
    "    \n",
    "    # Create transformation matrix (scale, rotation, reflection)\n",
    "    scale = np.sqrt(np.sum(mtx1[0]**2)) / np.sqrt(np.sum(target_coords[0]**2))\n",
    "    \n",
    "    # Apply transformation to all points in target_df\n",
    "    result_df = target_df.copy()\n",
    "    coords = result_df[['x', 'y']].values\n",
    "    \n",
    "    # Scale and center (simplified Procrustes)\n",
    "    coords_scaled = coords * scale\n",
    "    \n",
    "    # Get centroids\n",
    "    target_centroid = np.mean(target_coords, axis=0)\n",
    "    reference_centroid = np.mean(reference_coords, axis=0)\n",
    "    \n",
    "    # Translate\n",
    "    coords_transformed = coords_scaled - target_centroid + reference_centroid\n",
    "    \n",
    "    # Update dataframe\n",
    "    result_df['x'] = coords_transformed[:, 0]\n",
    "    result_df['y'] = coords_transformed[:, 1]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Compute coordinates for the first year (reference)\n",
    "method = 'pca'  # PCA is more stable for small numbers of points\n",
    "reference_data = get_coordinates(similarity_matrices[policy_area][years[0]], method=method)\n",
    "\n",
    "# Compute and align coordinates for all years\n",
    "aligned_data = {}\n",
    "for year in years:\n",
    "    # Compute initial coordinates\n",
    "    year_data = get_coordinates(similarity_matrices[policy_area][year], method=method)\n",
    "    \n",
    "    # Align with reference\n",
    "    if year == years[0]:\n",
    "        aligned_data[year] = year_data  # Reference year doesn't need alignment\n",
    "    else:\n",
    "        aligned_data[year] = align_coordinates(year_data, reference_data)\n",
    "\n",
    "# Find the overall range of data across all years to set consistent plot boundaries\n",
    "all_x = []\n",
    "all_y = []\n",
    "for year_data in aligned_data.values():\n",
    "    all_x.extend(year_data['x'])\n",
    "    all_y.extend(year_data['y'])\n",
    "\n",
    "x_min, x_max = min(all_x), max(all_x)\n",
    "y_min, y_max = min(all_y), max(all_y)\n",
    "\n",
    "# Add padding (200% zoom - 50% padding on each side)\n",
    "padding_x = (x_max - x_min) * 0.5\n",
    "padding_y = (y_max - y_min) * 0.5\n",
    "x_range = (x_min - padding_x, x_max + padding_x)\n",
    "y_range = (y_min - padding_y, y_max + padding_y)\n",
    "\n",
    "# Create initial plot with first year\n",
    "current_year = years[0]\n",
    "init_data = aligned_data[current_year]\n",
    "\n",
    "# Create ColumnDataSource\n",
    "source = ColumnDataSource(init_data)\n",
    "\n",
    "# Create the figure with fixed range\n",
    "p = figure(width=700, height=500, \n",
    "           title=f'EPG Clustering - {policy_area} ({current_year})',\n",
    "           tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "           x_range=Range1d(x_range[0], x_range[1]),\n",
    "           y_range=Range1d(y_range[0], y_range[1]))\n",
    "\n",
    "# Add scatter points\n",
    "p.circle('x', 'y', source=source, size=15, color='color', alpha=0.8, \n",
    "         line_color='black', line_width=1)\n",
    "\n",
    "# Add labels\n",
    "labels = LabelSet(x='x', y='y', text='epg', source=source,\n",
    "                 text_font_size='10pt', text_color='black',\n",
    "                 x_offset=5, y_offset=5)\n",
    "p.add_layout(labels)\n",
    "\n",
    "# Prepare data for JavaScript\n",
    "js_data = {}\n",
    "for year in years:\n",
    "    js_data[str(year)] = aligned_data[year].to_dict('list')\n",
    "\n",
    "# Create a slider for years\n",
    "year_slider = Slider(title=\"Year\", start=0, end=len(years)-1, value=0, step=1, width=600)\n",
    "\n",
    "# Create play/pause button\n",
    "play_button = Button(label=\"‚ñ∂Ô∏è Play\", button_type=\"success\", width=100)\n",
    "\n",
    "# JavaScript callback for slider\n",
    "slider_callback = CustomJS(args=dict(source=source, p=p, years=years, \n",
    "                                   policy_area=policy_area, data=js_data), code=\"\"\"\n",
    "    // Get the selected year index\n",
    "    const yearIndex = cb_obj.value;\n",
    "    const year = years[yearIndex];\n",
    "    \n",
    "    // Update data from precomputed results\n",
    "    const year_data = data[year];\n",
    "    \n",
    "    // Update the source data\n",
    "    source.data['x'] = year_data['x'];\n",
    "    source.data['y'] = year_data['y'];\n",
    "    source.data['epg'] = year_data['epg'];\n",
    "    source.data['color'] = year_data['color'];\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = `EPG Clustering - ${policy_area} (${year})`;\n",
    "    \n",
    "    // Trigger update\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Connect callback to slider\n",
    "year_slider.js_on_change('value', slider_callback)\n",
    "\n",
    "# Animation callback for play button\n",
    "animation_callback = CustomJS(args=dict(slider=year_slider, button=play_button), code=\"\"\"\n",
    "    if (button.label === \"‚ñ∂Ô∏è Play\") {\n",
    "        // Start animation\n",
    "        button.label = \"‚è∏Ô∏è Pause\";\n",
    "        \n",
    "        // Function to increment slider\n",
    "        function animate_slider() {\n",
    "            if (button.label === \"‚è∏Ô∏è Pause\") {\n",
    "                let current = slider.value;\n",
    "                let next = current + 1;\n",
    "                \n",
    "                // Loop back to beginning if at the end\n",
    "                if (next > slider.end) {\n",
    "                    next = slider.start;\n",
    "                }\n",
    "                \n",
    "                // Update slider value (this will trigger the slider callback)\n",
    "                slider.value = next;\n",
    "                \n",
    "                // Schedule next update\n",
    "                window.setTimeout(animate_slider, 1000);  // 1 second interval\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Start animation\n",
    "        animate_slider();\n",
    "    } else {\n",
    "        // Pause animation\n",
    "        button.label = \"‚ñ∂Ô∏è Play\";\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# Connect animation callback to play button\n",
    "play_button.js_on_click(animation_callback)\n",
    "\n",
    "# Create layout\n",
    "layout = column(\n",
    "    row(year_slider, play_button),\n",
    "    p\n",
    ")\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "save(layout)\n",
    "\n",
    "print(\"Visualization saved to 'epg_clustering_animation.html'. Open this file in a web browser to view the animation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated over all policy areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9811908320876931' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.41345291479820634' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7746469446489526' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9911132952474557' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9905551012338578' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9434529147982064' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9811908320876931' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8183888898602649' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7549298105763774' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8555191882111719' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8301782675672886' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8026154121325444' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9474908526755048' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8183888898602649' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.900270197716128' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7291610353650242' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8786452451598625' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8717396947357492' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.944440033871285' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8835184373533718' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.900270197716128' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9224390720755818' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8555929176437406' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8552465726920219' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.920487543876322' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9387628993809322' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.918023757064853' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9224390720755818' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9245264823582422' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7368357193060333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.835784762753872' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9776840656900007' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9916285005012252' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9031426518426579' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9245264823582422' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9378430438231742' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.77164534191569' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8346325977241078' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8554930368772125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9842433593574075' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8639211923936095' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9378430438231742' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7112296159832655' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8733598567269584' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8753841482249342' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9884263593070793' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8783110048733087' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7769131296436578' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7112296159832655' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8902319786251737' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7929745570189884' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8323160663427871' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9438117730086675' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9316880357470751' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.908388077918433' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8902319786251737' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9123113034739372' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8636355689775467' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8263676700272032' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.922288604821864' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9426849338057998' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.85406535829458' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9123113034739372' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9940648222858414' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8833370635623589' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8571524788250956' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9450420313703413' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9955799747404973' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8876955396249341' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9940648222858414' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6458374220034513' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7456315278609521' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7092947373106785' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9286807818505304' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9593860372666864' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8443859989814139' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6458374220034513' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4989475879854369' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6467521110700197' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7610026041666667' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9562353028671804' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8515728753547519' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4622757523148148' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4989475879854369' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7784057971014492' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6435859417902251' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7007609860664522' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9268208031875852' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9565845755022683' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7864351851851851' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7784057971014492' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9783636848775933' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7508383026531846' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9061725414453565' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8505847953216373' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8812109137196302' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.904594820384294' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9783636848775933' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9225733679644406' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8060897915118781' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7934802388084263' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.954639200511787' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.942895469974976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8987104032135048' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9225733679644406' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9509666573269823' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7235971107661135' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7609639106928517' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8662350380490819' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9360035341950563' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8099589645492677' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9509666573269823' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9467549925459039' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8713305224352689' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.894977661669435' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.974534610176271' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9165415297648184' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9392484614127367' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9467549925459039' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.696722245513212' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8152299351163137' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8282210246096369' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9664026720976334' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7460250981254708' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6753531894242395' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.696722245513212' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to 'epg_clustering_all_policies_merged.html'. Open this file in a web browser to view the animation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9043799784714747' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9179732776497493' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.915563344770738' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9743698174806893' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9780195333267352' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8820273214666438' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "/var/folders/6w/0k457k8x1_97tynsvrbjwdgc0000gn/T/ipykernel_80649/1900812374.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9043799784714747' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from bokeh.plotting import figure, save, output_file\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Slider, CustomJS, Button, Range1d\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "# Set output to an HTML file\n",
    "output_file(\"epg_clustering_all_policies_merged.html\")\n",
    "\n",
    "# Merge data from all policy areas for each year\n",
    "merged_similarity_matrices = {}\n",
    "\n",
    "# Get all unique years across all policy areas\n",
    "all_years = set()\n",
    "for policy_area in similarity_matrices:\n",
    "    all_years.update(similarity_matrices[policy_area].keys())\n",
    "all_years = sorted(all_years)\n",
    "\n",
    "# Get all unique EPGs\n",
    "all_epgs = set()\n",
    "for policy_area in similarity_matrices:\n",
    "    for year in similarity_matrices[policy_area]:\n",
    "        all_epgs.update(similarity_matrices[policy_area][year].index)\n",
    "all_epgs = sorted(list(all_epgs))\n",
    "\n",
    "# Merge data for each year by averaging similarity scores across policy areas\n",
    "for year in all_years:\n",
    "    # Create a DataFrame with zeros for all EPG pairs\n",
    "    merged_matrix = pd.DataFrame(0, index=all_epgs, columns=all_epgs)\n",
    "    count_matrix = pd.DataFrame(0, index=all_epgs, columns=all_epgs)\n",
    "    \n",
    "    # Add similarity scores from each policy area\n",
    "    for policy_area in similarity_matrices:\n",
    "        if year in similarity_matrices[policy_area]:\n",
    "            policy_matrix = similarity_matrices[policy_area][year]\n",
    "            for epg1 in policy_matrix.index:\n",
    "                for epg2 in policy_matrix.columns:\n",
    "                    if epg1 in merged_matrix.index and epg2 in merged_matrix.columns:\n",
    "                        merged_matrix.loc[epg1, epg2] += policy_matrix.loc[epg1, epg2]\n",
    "                        count_matrix.loc[epg1, epg2] += 1\n",
    "    \n",
    "    # Average the similarity scores\n",
    "    for epg1 in merged_matrix.index:\n",
    "        for epg2 in merged_matrix.columns:\n",
    "            if count_matrix.loc[epg1, epg2] > 0:\n",
    "                merged_matrix.loc[epg1, epg2] /= count_matrix.loc[epg1, epg2]\n",
    "            else:\n",
    "                # No data for this pair, set to 0 if different EPGs, 1 if same EPG\n",
    "                merged_matrix.loc[epg1, epg2] = 1.0 if epg1 == epg2 else 0.0\n",
    "    \n",
    "    # Store the merged matrix\n",
    "    merged_similarity_matrices[year] = merged_matrix\n",
    "\n",
    "# Get years with enough data\n",
    "years = [year for year in all_years if len(merged_similarity_matrices[year]) >= 3]\n",
    "\n",
    "# Make sure we have at least one valid year\n",
    "if not years:\n",
    "    raise ValueError(\"No years have enough EPGs for visualization\")\n",
    "\n",
    "# Get EPGs from the first year\n",
    "epgs = list(merged_similarity_matrices[years[0]].index)\n",
    "\n",
    "# Create color mapping for EPGs\n",
    "epg_colors = {}\n",
    "palette = Category10[10]\n",
    "for i, epg in enumerate(epgs):\n",
    "    epg_colors[epg] = palette[i % len(palette)]\n",
    "\n",
    "# Function to perform dimensionality reduction on a similarity matrix\n",
    "def get_coordinates(similarity_matrix, method='pca'):\n",
    "    # Convert similarity to distance matrix\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    X = distance_matrix.values\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    if method == 'pca':\n",
    "        model = PCA(n_components=2)\n",
    "        result = model.fit_transform(X)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    df_result = pd.DataFrame({\n",
    "        'x': result[:, 0],\n",
    "        'y': result[:, 1],\n",
    "        'epg': distance_matrix.index,\n",
    "        'color': [epg_colors.get(epg, '#000000') for epg in distance_matrix.index]\n",
    "    })\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Function to align coordinates with reference using Procrustes analysis\n",
    "def align_coordinates(target_df, reference_df):\n",
    "    # Get common EPGs\n",
    "    common_epgs = set(target_df['epg']).intersection(set(reference_df['epg']))\n",
    "    \n",
    "    if len(common_epgs) < 2:\n",
    "        # Not enough common points to align\n",
    "        return target_df\n",
    "    \n",
    "    # Extract coordinates for common EPGs\n",
    "    target_coords = np.array([target_df[target_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "    reference_coords = np.array([reference_df[reference_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "    \n",
    "    # Perform Procrustes analysis to align target to reference\n",
    "    mtx1, mtx2, disparity = procrustes(reference_coords, target_coords)\n",
    "    \n",
    "    # Create transformation matrix (scale, rotation, reflection)\n",
    "    scale = np.sqrt(np.sum(mtx1[0]**2)) / np.sqrt(np.sum(target_coords[0]**2))\n",
    "    \n",
    "    # Apply transformation to all points in target_df\n",
    "    result_df = target_df.copy()\n",
    "    coords = result_df[['x', 'y']].values\n",
    "    \n",
    "    # Scale and center (simplified Procrustes)\n",
    "    coords_scaled = coords * scale\n",
    "    \n",
    "    # Get centroids\n",
    "    target_centroid = np.mean(target_coords, axis=0)\n",
    "    reference_centroid = np.mean(reference_coords, axis=0)\n",
    "    \n",
    "    # Translate\n",
    "    coords_transformed = coords_scaled - target_centroid + reference_centroid\n",
    "    \n",
    "    # Update dataframe\n",
    "    result_df['x'] = coords_transformed[:, 0]\n",
    "    result_df['y'] = coords_transformed[:, 1]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Compute coordinates for the first year (reference)\n",
    "method = 'pca'  # PCA is more stable for small numbers of points\n",
    "reference_data = get_coordinates(merged_similarity_matrices[years[0]], method=method)\n",
    "\n",
    "# Compute and align coordinates for all years\n",
    "aligned_data = {}\n",
    "for year in years:\n",
    "    try:\n",
    "        # Compute initial coordinates\n",
    "        year_data = get_coordinates(merged_similarity_matrices[year], method=method)\n",
    "        \n",
    "        # Align with reference\n",
    "        if year == years[0]:\n",
    "            aligned_data[year] = year_data  # Reference year doesn't need alignment\n",
    "        else:\n",
    "            aligned_data[year] = align_coordinates(year_data, reference_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")\n",
    "        # Skip this year\n",
    "\n",
    "# Make sure we have at least one valid year after processing\n",
    "if not aligned_data:\n",
    "    raise ValueError(\"No valid data after processing\")\n",
    "\n",
    "# Find the overall range of data across all years to set consistent plot boundaries\n",
    "all_x = []\n",
    "all_y = []\n",
    "for year_data in aligned_data.values():\n",
    "    all_x.extend(year_data['x'])\n",
    "    all_y.extend(year_data['y'])\n",
    "\n",
    "x_min, x_max = min(all_x), max(all_x)\n",
    "y_min, y_max = min(all_y), max(all_y)\n",
    "\n",
    "# Add padding (200% zoom - 50% padding on each side)\n",
    "padding_x = (x_max - x_min) * 0.5\n",
    "padding_y = (y_max - y_min) * 0.5\n",
    "x_range = (x_min - padding_x, x_max + padding_x)\n",
    "y_range = (y_min - padding_y, y_max + padding_y)\n",
    "\n",
    "# Create initial plot with first year\n",
    "current_year = years[0]\n",
    "init_data = aligned_data[current_year]\n",
    "\n",
    "# Create ColumnDataSource\n",
    "source = ColumnDataSource(init_data)\n",
    "\n",
    "# Create the figure with fixed range\n",
    "p = figure(width=800, height=600, \n",
    "           title=f'EPG Clustering - All Policy Areas Combined ({current_year})',\n",
    "           tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "           x_range=Range1d(x_range[0], x_range[1]),\n",
    "           y_range=Range1d(y_range[0], y_range[1]))\n",
    "\n",
    "# Add scatter points\n",
    "p.circle('x', 'y', source=source, size=15, color='color', alpha=0.8, \n",
    "         line_color='black', line_width=1)\n",
    "\n",
    "# Add labels\n",
    "labels = LabelSet(x='x', y='y', text='epg', source=source,\n",
    "                 text_font_size='10pt', text_color='black',\n",
    "                 x_offset=5, y_offset=5)\n",
    "p.add_layout(labels)\n",
    "\n",
    "# Prepare data for JavaScript\n",
    "js_data = {}\n",
    "for year in aligned_data.keys():\n",
    "    js_data[str(year)] = aligned_data[year].to_dict('list')\n",
    "\n",
    "# Get sorted years that have data\n",
    "valid_years = sorted(aligned_data.keys())\n",
    "\n",
    "# Create a slider for years\n",
    "year_slider = Slider(title=\"Year\", start=0, end=len(valid_years)-1, value=0, step=1, width=600)\n",
    "\n",
    "# Create play/pause button\n",
    "play_button = Button(label=\"‚ñ∂Ô∏è Play\", button_type=\"success\", width=100)\n",
    "\n",
    "# JavaScript callback for slider\n",
    "slider_callback = CustomJS(args=dict(source=source, p=p, years=valid_years, data=js_data), code=\"\"\"\n",
    "    // Get the selected year index\n",
    "    const yearIndex = cb_obj.value;\n",
    "    const year = years[yearIndex];\n",
    "    \n",
    "    // Update data from precomputed results\n",
    "    const year_data = data[year];\n",
    "    \n",
    "    // Update the source data\n",
    "    source.data['x'] = year_data['x'];\n",
    "    source.data['y'] = year_data['y'];\n",
    "    source.data['epg'] = year_data['epg'];\n",
    "    source.data['color'] = year_data['color'];\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = `EPG Clustering - All Policy Areas Combined (${year})`;\n",
    "    \n",
    "    // Trigger update\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Connect callback to slider\n",
    "year_slider.js_on_change('value', slider_callback)\n",
    "\n",
    "# Animation callback for play button\n",
    "animation_callback = CustomJS(args=dict(slider=year_slider, button=play_button), code=\"\"\"\n",
    "    if (button.label === \"‚ñ∂Ô∏è Play\") {\n",
    "        // Start animation\n",
    "        button.label = \"‚è∏Ô∏è Pause\";\n",
    "        \n",
    "        // Function to increment slider\n",
    "        function animate_slider() {\n",
    "            if (button.label === \"‚è∏Ô∏è Pause\") {\n",
    "                let current = slider.value;\n",
    "                let next = current + 1;\n",
    "                \n",
    "                // Loop back to beginning if at the end\n",
    "                if (next > slider.end) {\n",
    "                    next = slider.start;\n",
    "                }\n",
    "                \n",
    "                // Update slider value (this will trigger the slider callback)\n",
    "                slider.value = next;\n",
    "                \n",
    "                // Schedule next update\n",
    "                window.setTimeout(animate_slider, 1000);  // 1 second interval\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Start animation\n",
    "        animate_slider();\n",
    "    } else {\n",
    "        // Pause animation\n",
    "        button.label = \"‚ñ∂Ô∏è Play\";\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# Connect animation callback to play button\n",
    "play_button.js_on_click(animation_callback)\n",
    "\n",
    "# Create layout\n",
    "layout = column(\n",
    "    row(year_slider, play_button),\n",
    "    p\n",
    ")\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "save(layout)\n",
    "\n",
    "print(\"Visualization saved to 'epg_clustering_all_policies_merged.html'. Open this file in a web browser to view the animation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive verison with selecte clustering and policy area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pca for agriculture...\n",
      "Computing tsne for agriculture...\n",
      "Computing pca for budget...\n",
      "Computing tsne for budget...\n",
      "Computing pca for budgetary control...\n",
      "Computing tsne for budgetary control...\n",
      "Computing pca for civil liberties justice home affairs...\n",
      "Computing tsne for civil liberties justice home affairs...\n",
      "Computing pca for constitutional inter institutional affairs...\n",
      "Computing tsne for constitutional inter institutional affairs...\n",
      "Computing pca for culture education...\n",
      "Computing tsne for culture education...\n",
      "Computing pca for development...\n",
      "Computing tsne for development...\n",
      "Computing pca for economic monetary affairs...\n",
      "Computing tsne for economic monetary affairs...\n",
      "Computing pca for economics...\n",
      "Computing tsne for economics...\n",
      "Computing pca for employment social affairs...\n",
      "Computing tsne for employment social affairs...\n",
      "Computing pca for environment public health...\n",
      "Computing tsne for environment public health...\n",
      "Computing pca for fisheries...\n",
      "Computing tsne for fisheries...\n",
      "Computing pca for foreign security policy...\n",
      "Computing tsne for foreign security policy...\n",
      "Computing pca for gender equality...\n",
      "Computing tsne for gender equality...\n",
      "Computing pca for industry research energy...\n",
      "Computing tsne for industry research energy...\n",
      "Computing pca for internal market consumer protection...\n",
      "Computing tsne for internal market consumer protection...\n",
      "Computing pca for internal regulations of the ep...\n",
      "Computing tsne for internal regulations of the ep...\n",
      "Computing pca for international trade...\n",
      "Computing tsne for international trade...\n",
      "Computing pca for juridical affairs...\n",
      "Computing tsne for juridical affairs...\n",
      "Computing pca for legal affairs...\n",
      "Computing tsne for legal affairs...\n",
      "Computing pca for petitions...\n",
      "Computing tsne for petitions...\n",
      "Computing pca for regional development...\n",
      "Computing tsne for regional development...\n",
      "Computing pca for transport tourism...\n",
      "Computing tsne for transport tourism...\n",
      "Visualization saved to 'epg_clustering_interactive.html'. Open this file in a web browser to interact with the visualization.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import procrustes\n",
    "from bokeh.plotting import figure, save, output_file\n",
    "from bokeh.models import (ColumnDataSource, LabelSet, Slider, CustomJS, Button, \n",
    "                         Range1d, Select, RadioButtonGroup)\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "# Set output to an HTML file\n",
    "output_file(\"epg_clustering_interactive.html\")\n",
    "\n",
    "# Get all available policy areas\n",
    "policy_areas = sorted(similarity_matrices.keys())\n",
    "\n",
    "# Create a function that will generate aligned coordinates for a given policy area and method\n",
    "def generate_coordinates(policy_area, method='pca'):\n",
    "    # Get years for this policy area\n",
    "    years = sorted(similarity_matrices[policy_area].keys())\n",
    "    \n",
    "    # Get EPGs from the first year\n",
    "    epgs = list(similarity_matrices[policy_area][years[0]].index)\n",
    "    \n",
    "    # Create color mapping for EPGs\n",
    "    epg_colors = {}\n",
    "    palette = Category10[10]\n",
    "    for i, epg in enumerate(epgs):\n",
    "        epg_colors[epg] = palette[i % len(palette)]\n",
    "    \n",
    "    # Function to perform dimensionality reduction on a similarity matrix\n",
    "    def get_coordinates(similarity_matrix):\n",
    "        # Convert similarity to distance matrix\n",
    "        distance_matrix = 1 - similarity_matrix\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        X = distance_matrix.values\n",
    "        \n",
    "        # Apply dimensionality reduction\n",
    "        if method == 'pca':\n",
    "            model = PCA(n_components=2)\n",
    "            result = model.fit_transform(X)\n",
    "        elif method == 'tsne':\n",
    "            # Use lower perplexity for small datasets\n",
    "            perplexity = min(5, max(1, len(X) // 2))\n",
    "            model = TSNE(n_components=2, perplexity=perplexity, \n",
    "                        random_state=42, learning_rate='auto', init='pca')\n",
    "            result = model.fit_transform(X)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        # Create DataFrame with results\n",
    "        df_result = pd.DataFrame({\n",
    "            'x': result[:, 0],\n",
    "            'y': result[:, 1],\n",
    "            'epg': distance_matrix.index,\n",
    "            'color': [epg_colors.get(epg, '#000000') for epg in distance_matrix.index]\n",
    "        })\n",
    "        \n",
    "        return df_result\n",
    "    \n",
    "    # Function to align coordinates with reference using Procrustes analysis\n",
    "    def align_coordinates(target_df, reference_df):\n",
    "        # Get common EPGs\n",
    "        common_epgs = set(target_df['epg']).intersection(set(reference_df['epg']))\n",
    "        \n",
    "        if len(common_epgs) < 2:\n",
    "            # Not enough common points to align\n",
    "            return target_df\n",
    "        \n",
    "        # Extract coordinates for common EPGs\n",
    "        target_coords = np.array([target_df[target_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "        reference_coords = np.array([reference_df[reference_df['epg'] == epg][['x', 'y']].values[0] for epg in common_epgs])\n",
    "        \n",
    "        # Perform Procrustes analysis to align target to reference\n",
    "        mtx1, mtx2, disparity = procrustes(reference_coords, target_coords)\n",
    "        \n",
    "        # Create transformation matrix (scale, rotation, reflection)\n",
    "        scale = np.sqrt(np.sum(mtx1[0]**2)) / np.sqrt(np.sum(target_coords[0]**2))\n",
    "        \n",
    "        # Apply transformation to all points in target_df\n",
    "        result_df = target_df.copy()\n",
    "        coords = result_df[['x', 'y']].values\n",
    "        \n",
    "        # Scale and center (simplified Procrustes)\n",
    "        coords_scaled = coords * scale\n",
    "        \n",
    "        # Get centroids\n",
    "        target_centroid = np.mean(target_coords, axis=0)\n",
    "        reference_centroid = np.mean(reference_coords, axis=0)\n",
    "        \n",
    "        # Translate\n",
    "        coords_transformed = coords_scaled - target_centroid + reference_centroid\n",
    "        \n",
    "        # Update dataframe\n",
    "        result_df['x'] = coords_transformed[:, 0]\n",
    "        result_df['y'] = coords_transformed[:, 1]\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    # Compute coordinates for the first year (reference)\n",
    "    reference_data = get_coordinates(similarity_matrices[policy_area][years[0]])\n",
    "    \n",
    "    # Compute and align coordinates for all years\n",
    "    aligned_data = {}\n",
    "    for year in years:\n",
    "        # Compute initial coordinates\n",
    "        year_data = get_coordinates(similarity_matrices[policy_area][year])\n",
    "        \n",
    "        # Align with reference\n",
    "        if year == years[0]:\n",
    "            aligned_data[year] = year_data  # Reference year doesn't need alignment\n",
    "        else:\n",
    "            aligned_data[year] = align_coordinates(year_data, reference_data)\n",
    "    \n",
    "    # Find the overall range of data across all years to set consistent plot boundaries\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for year_data in aligned_data.values():\n",
    "        all_x.extend(year_data['x'])\n",
    "        all_y.extend(year_data['y'])\n",
    "    \n",
    "    x_min, x_max = min(all_x), max(all_x)\n",
    "    y_min, y_max = min(all_y), max(all_y)\n",
    "    \n",
    "    # Add padding (200% zoom - 50% padding on each side)\n",
    "    padding_x = (x_max - x_min) * 0.5\n",
    "    padding_y = (y_max - y_min) * 0.5\n",
    "    x_range = (x_min - padding_x, x_max + padding_x)\n",
    "    y_range = (y_min - padding_y, y_max + padding_y)\n",
    "    \n",
    "    # Prepare data for JavaScript\n",
    "    js_data = {}\n",
    "    for year in years:\n",
    "        js_data[str(year)] = aligned_data[year].to_dict('list')\n",
    "    \n",
    "    return {\n",
    "        'years': years,\n",
    "        'data': js_data,\n",
    "        'init_data': aligned_data[years[0]],\n",
    "        'x_range': x_range,\n",
    "        'y_range': y_range\n",
    "    }\n",
    "\n",
    "# Generate initial data for the first policy area using PCA\n",
    "initial_policy = policy_areas[0]\n",
    "initial_method = 'pca'\n",
    "initial_data = generate_coordinates(initial_policy, initial_method)\n",
    "\n",
    "# Create ColumnDataSource\n",
    "source = ColumnDataSource(initial_data['init_data'])\n",
    "\n",
    "# Create the figure with fixed range\n",
    "p = figure(width=800, height=600, \n",
    "           title=f'EPG Clustering - {initial_policy} ({initial_data[\"years\"][0]})',\n",
    "           tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "           x_range=Range1d(initial_data['x_range'][0], initial_data['x_range'][1]),\n",
    "           y_range=Range1d(initial_data['y_range'][0], initial_data['y_range'][1]))\n",
    "\n",
    "# Add scatter points\n",
    "p.circle('x', 'y', source=source, size=15, color='color', alpha=0.8, \n",
    "         line_color='black', line_width=1)\n",
    "\n",
    "# Add labels\n",
    "labels = LabelSet(x='x', y='y', text='epg', source=source,\n",
    "                 text_font_size='10pt', text_color='black',\n",
    "                 x_offset=5, y_offset=5)\n",
    "p.add_layout(labels)\n",
    "\n",
    "# Create controls\n",
    "# Policy area dropdown\n",
    "policy_select = Select(title=\"Policy Area:\", value=initial_policy, options=policy_areas, width=200)\n",
    "\n",
    "# Clustering method selection\n",
    "method_group = RadioButtonGroup(labels=[\"PCA\", \"t-SNE\"], active=0, width=200)\n",
    "\n",
    "# Create a slider for years\n",
    "year_slider = Slider(title=\"Year\", start=0, end=len(initial_data['years'])-1, value=0, step=1, width=400)\n",
    "\n",
    "# Create play/pause button\n",
    "play_button = Button(label=\"‚ñ∂Ô∏è Play\", button_type=\"success\", width=100)\n",
    "\n",
    "# Precompute data for all policy areas and methods\n",
    "all_data = {}\n",
    "for policy in policy_areas:\n",
    "    all_data[policy] = {}\n",
    "    for method in ['pca', 'tsne']:\n",
    "        try:\n",
    "            print(f\"Computing {method} for {policy}...\")\n",
    "            all_data[policy][method] = generate_coordinates(policy, method)\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing {method} for {policy}: {e}\")\n",
    "            # Create empty placeholder\n",
    "            all_data[policy][method] = {\n",
    "                'years': [],\n",
    "                'data': {},\n",
    "                'init_data': pd.DataFrame(columns=['x', 'y', 'epg', 'color']),\n",
    "                'x_range': (-1, 1),\n",
    "                'y_range': (-1, 1)\n",
    "            }\n",
    "\n",
    "# JavaScript callback for policy area selection\n",
    "policy_callback = CustomJS(args=dict(source=source, p=p, year_slider=year_slider, \n",
    "                                   method_group=method_group, all_data=all_data), code=\"\"\"\n",
    "    // Get the selected policy area\n",
    "    const policy = cb_obj.value;\n",
    "    \n",
    "    // Get the currently selected method\n",
    "    const methods = ['pca', 'tsne'];\n",
    "    const method = methods[method_group.active];\n",
    "    \n",
    "    // Get data for this policy and method\n",
    "    const policy_data = all_data[policy][method];\n",
    "    const years = policy_data.years;\n",
    "    \n",
    "    // Update slider\n",
    "    year_slider.start = 0;\n",
    "    year_slider.end = years.length - 1;\n",
    "    year_slider.value = 0;\n",
    "    \n",
    "    // Get first year data\n",
    "    const year = years[0];\n",
    "    const year_data = policy_data.data[year];\n",
    "    \n",
    "    // Update the plot range\n",
    "    p.x_range.start = policy_data.x_range[0];\n",
    "    p.x_range.end = policy_data.x_range[1];\n",
    "    p.y_range.start = policy_data.y_range[0];\n",
    "    p.y_range.end = policy_data.y_range[1];\n",
    "    \n",
    "    // Update the source data\n",
    "    source.data['x'] = year_data['x'];\n",
    "    source.data['y'] = year_data['y'];\n",
    "    source.data['epg'] = year_data['epg'];\n",
    "    source.data['color'] = year_data['color'];\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = `EPG Clustering - ${policy} (${year})`;\n",
    "    \n",
    "    // Trigger update\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# JavaScript callback for method selection\n",
    "method_callback = CustomJS(args=dict(source=source, p=p, year_slider=year_slider, \n",
    "                                  policy_select=policy_select, all_data=all_data), code=\"\"\"\n",
    "    // Get the selected method\n",
    "    const methods = ['pca', 'tsne'];\n",
    "    const method = methods[cb_obj.active];\n",
    "    \n",
    "    // Get the currently selected policy\n",
    "    const policy = policy_select.value;\n",
    "    \n",
    "    // Get data for this policy and method\n",
    "    const policy_data = all_data[policy][method];\n",
    "    const years = policy_data.years;\n",
    "    \n",
    "    // Update slider\n",
    "    year_slider.start = 0;\n",
    "    year_slider.end = years.length - 1;\n",
    "    year_slider.value = 0;\n",
    "    \n",
    "    // Get first year data\n",
    "    const year = years[0];\n",
    "    const year_data = policy_data.data[year];\n",
    "    \n",
    "    // Update the plot range\n",
    "    p.x_range.start = policy_data.x_range[0];\n",
    "    p.x_range.end = policy_data.x_range[1];\n",
    "    p.y_range.start = policy_data.y_range[0];\n",
    "    p.y_range.end = policy_data.y_range[1];\n",
    "    \n",
    "    // Update the source data\n",
    "    source.data['x'] = year_data['x'];\n",
    "    source.data['y'] = year_data['y'];\n",
    "    source.data['epg'] = year_data['epg'];\n",
    "    source.data['color'] = year_data['color'];\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = `EPG Clustering - ${policy} (${year})`;\n",
    "    \n",
    "    // Trigger update\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# JavaScript callback for slider\n",
    "slider_callback = CustomJS(args=dict(source=source, p=p, policy_select=policy_select, \n",
    "                                  method_group=method_group, all_data=all_data), code=\"\"\"\n",
    "    // Get the selected policy and method\n",
    "    const policy = policy_select.value;\n",
    "    const methods = ['pca', 'tsne'];\n",
    "    const method = methods[method_group.active];\n",
    "    \n",
    "    // Get data for this policy and method\n",
    "    const policy_data = all_data[policy][method];\n",
    "    const years = policy_data.years;\n",
    "    \n",
    "    // Get the selected year index\n",
    "    const yearIndex = cb_obj.value;\n",
    "    const year = years[yearIndex];\n",
    "    \n",
    "    // Update data from precomputed results\n",
    "    const year_data = policy_data.data[year];\n",
    "    \n",
    "    // Update the source data\n",
    "    source.data['x'] = year_data['x'];\n",
    "    source.data['y'] = year_data['y'];\n",
    "    source.data['epg'] = year_data['epg'];\n",
    "    source.data['color'] = year_data['color'];\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = `EPG Clustering - ${policy} (${year})`;\n",
    "    \n",
    "    // Trigger update\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Animation callback for play button\n",
    "animation_callback = CustomJS(args=dict(slider=year_slider, button=play_button), code=\"\"\"\n",
    "    if (button.label === \"‚ñ∂Ô∏è Play\") {\n",
    "        // Start animation\n",
    "        button.label = \"‚è∏Ô∏è Pause\";\n",
    "        \n",
    "        // Function to increment slider\n",
    "        function animate_slider() {\n",
    "            if (button.label === \"‚è∏Ô∏è Pause\") {\n",
    "                let current = slider.value;\n",
    "                let next = current + 1;\n",
    "                \n",
    "                // Loop back to beginning if at the end\n",
    "                if (next > slider.end) {\n",
    "                    next = slider.start;\n",
    "                }\n",
    "                \n",
    "                // Update slider value (this will trigger the slider callback)\n",
    "                slider.value = next;\n",
    "                \n",
    "                // Schedule next update\n",
    "                window.setTimeout(animate_slider, 1000);  // 1 second interval\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Start animation\n",
    "        animate_slider();\n",
    "    } else {\n",
    "        // Pause animation\n",
    "        button.label = \"‚ñ∂Ô∏è Play\";\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# Connect callbacks\n",
    "policy_select.js_on_change('value', policy_callback)\n",
    "method_group.js_on_change('active', method_callback)\n",
    "year_slider.js_on_change('value', slider_callback)\n",
    "play_button.js_on_click(animation_callback)\n",
    "\n",
    "# Create layout\n",
    "controls = row(\n",
    "    column(\n",
    "        policy_select,\n",
    "        method_group\n",
    "    ),\n",
    "    column(\n",
    "        row(year_slider, play_button)\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = column(\n",
    "    controls,\n",
    "    p\n",
    ")\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "save(layout)\n",
    "\n",
    "print(\"Visualization saved to 'epg_clustering_interactive.html'. Open this file in a web browser to interact with the visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create directory for story plots if it doesn't exist\n",
    "os.makedirs(\"story_plots\", exist_ok=True)\n",
    "\n",
    "# Calculate polarization metrics\n",
    "def calculate_polarization_metrics(similarity_matrices):\n",
    "    \"\"\"Calculate cluster distance as a polarization metric for each year and policy area.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for policy_area in similarity_matrices:\n",
    "        metrics[policy_area] = {}\n",
    "        \n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            sim_matrix = similarity_matrices[policy_area][year]\n",
    "            \n",
    "            # Skip if we don't have enough EPGs\n",
    "            if len(sim_matrix) < 3:\n",
    "                continue\n",
    "                \n",
    "            # Convert similarity to distance\n",
    "            distance_matrix = 1 - sim_matrix\n",
    "            \n",
    "            # Calculate average distance (higher = more polarized)\n",
    "            avg_distance = np.mean(distance_matrix.values[~np.eye(len(distance_matrix), dtype=bool)])\n",
    "            \n",
    "            # Calculate variance of distances (higher = more uneven polarization)\n",
    "            var_distance = np.var(distance_matrix.values[~np.eye(len(distance_matrix), dtype=bool)])\n",
    "            \n",
    "            # Store metrics\n",
    "            metrics[policy_area][year] = {\n",
    "                'avg_distance': avg_distance,\n",
    "                'var_distance': var_distance,\n",
    "                'num_epgs': len(sim_matrix)\n",
    "            }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ----------------------\n",
    "# PART 1: Overview Heatmap\n",
    "# ----------------------\n",
    "\n",
    "def create_overview_heatmap(similarity_matrices):\n",
    "    \"\"\"Create an aggregate heatmap of EPG similarities across all years and policy areas.\"\"\"\n",
    "    \n",
    "    # Get all unique EPGs\n",
    "    all_epgs = set()\n",
    "    for policy_area in similarity_matrices:\n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            matrix = similarity_matrices[policy_area][year]\n",
    "            all_epgs.update(matrix.index)\n",
    "    \n",
    "    all_epgs = sorted(list(all_epgs))\n",
    "    \n",
    "    # Create an aggregate similarity matrix\n",
    "    aggregate_matrix = pd.DataFrame(0.0, index=all_epgs, columns=all_epgs)\n",
    "    count_matrix = pd.DataFrame(0, index=all_epgs, columns=all_epgs)\n",
    "    \n",
    "    # Sum all similarity matrices\n",
    "    for policy_area in similarity_matrices:\n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            matrix = similarity_matrices[policy_area][year]\n",
    "            for i in matrix.index:\n",
    "                for j in matrix.columns:\n",
    "                    aggregate_matrix.loc[i, j] += matrix.loc[i, j]\n",
    "                    count_matrix.loc[i, j] += 1\n",
    "    \n",
    "    # Average the similarities\n",
    "    for i in aggregate_matrix.index:\n",
    "        for j in aggregate_matrix.columns:\n",
    "            if count_matrix.loc[i, j] > 0:\n",
    "                aggregate_matrix.loc[i, j] /= count_matrix.loc[i, j]\n",
    "            else:\n",
    "                # If no data, set to NaN (will be shown as white/missing in heatmap)\n",
    "                aggregate_matrix.loc[i, j] = np.nan\n",
    "    \n",
    "    # Set diagonal to 1 (self-similarity)\n",
    "    for i in aggregate_matrix.index:\n",
    "        aggregate_matrix.loc[i, i] = 1.0\n",
    "    \n",
    "    # Create the heatmap figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Use a diverging colormap (blue to red)\n",
    "    cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    sns.heatmap(aggregate_matrix, cmap=cmap, center=0.5,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .8},\n",
    "                vmin=0, vmax=1)\n",
    "    \n",
    "    plt.title('Overview: Average EPG Voting Similarity Across All Years and Policy Areas', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/1_overview_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return aggregate_matrix\n",
    "\n",
    "# ----------------------\n",
    "# PART 2: PCA Visualization\n",
    "# ----------------------\n",
    "\n",
    "def create_pca_visualization(aggregate_matrix):\n",
    "    \"\"\"Create a PCA visualization of EPG positions based on aggregate similarity.\"\"\"\n",
    "    \n",
    "    # Clean the matrix (replace NaN with 0)\n",
    "    clean_matrix = aggregate_matrix.fillna(0)\n",
    "    \n",
    "    # Convert similarity to distance\n",
    "    distance_matrix = 1 - clean_matrix\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(distance_matrix)\n",
    "    \n",
    "    # Create a DataFrame for the results\n",
    "    pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'], index=distance_matrix.index)\n",
    "    \n",
    "    # Organize EPGs into known political groups (rough approximation)\n",
    "    # You'll need to adapt this based on your actual data\n",
    "    political_spectrum = {\n",
    "        'Left': ['GUE/NGL', 'G/EFA', 'LEFT'], \n",
    "        'Center-Left': ['S&D', 'SOC'],\n",
    "        'Center': ['ALDE', 'RENEW'],\n",
    "        'Center-Right': ['EPP', 'PPE', 'ECR'],\n",
    "        'Right': ['ID', 'EFD', 'ENF', 'NI', 'EFDD', 'IND/DEM']\n",
    "    }\n",
    "    \n",
    "    # Define colors for the political spectrum\n",
    "    colors = {\n",
    "        'Left': 'darkred',\n",
    "        'Center-Left': 'tomato',\n",
    "        'Center': 'purple',\n",
    "        'Center-Right': 'royalblue',\n",
    "        'Right': 'darkblue'\n",
    "    }\n",
    "    \n",
    "    # Create the PCA visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot each EPG\n",
    "    for epg in pca_df.index:\n",
    "        # Find which group this EPG belongs to\n",
    "        group = next((g for g, epgs in political_spectrum.items() if epg in epgs), 'Other')\n",
    "        color = colors.get(group, 'gray')\n",
    "        \n",
    "        plt.scatter(pca_df.loc[epg, 'PC1'], pca_df.loc[epg, 'PC2'], \n",
    "                   color=color, s=100, alpha=0.7, edgecolors='black')\n",
    "        plt.text(pca_df.loc[epg, 'PC1']+0.01, pca_df.loc[epg, 'PC2']+0.01, \n",
    "                epg, fontsize=12)\n",
    "    \n",
    "    # Add a legend\n",
    "    for group, color in colors.items():\n",
    "        plt.scatter([], [], color=color, label=group, s=100, alpha=0.7, edgecolors='black')\n",
    "    plt.legend(title='Political Spectrum', fontsize=12)\n",
    "    \n",
    "    # Add labels and title\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    plt.xlabel(f'Principal Component 1 ({explained_var[0]:.2%} variance)', fontsize=12)\n",
    "    plt.ylabel(f'Principal Component 2 ({explained_var[1]:.2%} variance)', fontsize=12)\n",
    "    plt.title('PCA: EPG Positioning Based on Voting Similarities', fontsize=14)\n",
    "    \n",
    "    # Add grid lines\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/2_pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return pca_df\n",
    "\n",
    "# ----------------------\n",
    "# PART 3: Time Series Analysis\n",
    "# ----------------------\n",
    "\n",
    "def create_polarization_time_series(similarity_matrices, polarization_metrics):\n",
    "    \"\"\"Create time series plots of polarization metrics.\"\"\"\n",
    "    \n",
    "    # Create a time series of metrics for each policy area\n",
    "    time_series_data = {}\n",
    "    \n",
    "    for policy_area in polarization_metrics:\n",
    "        years = sorted(polarization_metrics[policy_area].keys())\n",
    "        \n",
    "        avg_distances = [polarization_metrics[policy_area][year]['avg_distance'] \n",
    "                        if year in polarization_metrics[policy_area] else None \n",
    "                        for year in years]\n",
    "        \n",
    "        var_distances = [polarization_metrics[policy_area][year]['var_distance'] \n",
    "                        if year in polarization_metrics[policy_area] else None \n",
    "                        for year in years]\n",
    "        \n",
    "        num_epgs = [polarization_metrics[policy_area][year]['num_epgs'] \n",
    "                   if year in polarization_metrics[policy_area] else None \n",
    "                   for year in years]\n",
    "        \n",
    "        time_series_data[policy_area] = {\n",
    "            'years': years,\n",
    "            'avg_distance': avg_distances,\n",
    "            'var_distance': var_distances,\n",
    "            'num_epgs': num_epgs\n",
    "        }\n",
    "    \n",
    "    # Find policy areas with most consistent data\n",
    "    complete_policy_areas = []\n",
    "    for policy_area, data in time_series_data.items():\n",
    "        non_null_values = [x for x in data['avg_distance'] if x is not None]\n",
    "        if len(non_null_values) > 5:  # At least 5 years of data\n",
    "            complete_policy_areas.append(policy_area)\n",
    "    \n",
    "    # Calculate average polarization across all policy areas by year\n",
    "    all_years = set()\n",
    "    for policy_area in polarization_metrics:\n",
    "        all_years.update(polarization_metrics[policy_area].keys())\n",
    "    all_years = sorted(all_years)\n",
    "    \n",
    "    avg_polarization_by_year = {}\n",
    "    for year in all_years:\n",
    "        values = []\n",
    "        for policy_area in polarization_metrics:\n",
    "            if year in polarization_metrics[policy_area]:\n",
    "                values.append(polarization_metrics[policy_area][year]['avg_distance'])\n",
    "        \n",
    "        if values:\n",
    "            avg_polarization_by_year[year] = np.mean(values)\n",
    "    \n",
    "    # Create time series plot for average polarization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    years = sorted(avg_polarization_by_year.keys())\n",
    "    values = [avg_polarization_by_year[year] for year in years]\n",
    "    \n",
    "    plt.plot(years, values, 'o-', color='black', linewidth=2.5, label='Average Across All Areas')\n",
    "    \n",
    "    # Select a few interesting policy areas to highlight\n",
    "    interesting_areas = []\n",
    "    for policy_area in complete_policy_areas:\n",
    "        data = time_series_data[policy_area]\n",
    "        non_null_distances = [d for d in data['avg_distance'] if d is not None]\n",
    "        if non_null_distances:\n",
    "            variance = np.var(non_null_distances)\n",
    "            trend = np.polyfit([i for i, d in enumerate(data['avg_distance']) if d is not None], \n",
    "                               [d for d in data['avg_distance'] if d is not None], 1)[0]\n",
    "            interesting_areas.append((policy_area, variance, trend))\n",
    "    \n",
    "    # Sort by variance (most varying first)\n",
    "    interesting_areas.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Plot top 5 most interesting policy areas\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, 5))\n",
    "    for i, (policy_area, _, _) in enumerate(interesting_areas[:5]):\n",
    "        data = time_series_data[policy_area]\n",
    "        valid_years = [year for i, year in enumerate(data['years']) if data['avg_distance'][i] is not None]\n",
    "        valid_values = [val for val in data['avg_distance'] if val is not None]\n",
    "        \n",
    "        if valid_years and valid_values:\n",
    "            plt.plot(valid_years, valid_values, 'o-', color=colors[i], linewidth=1.5, label=policy_area)\n",
    "    \n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Polarization (Average Distance)', fontsize=12)\n",
    "    plt.title('Polarization Trends Over Time by Policy Area', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title='Policy Area', fontsize=10)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/3_polarization_time_series.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return time_series_data, avg_polarization_by_year, interesting_areas\n",
    "\n",
    "# ----------------------\n",
    "# PART 4: Policy Area Ranking\n",
    "# ----------------------\n",
    "\n",
    "def create_policy_area_ranking(polarization_metrics, avg_polarization_by_year):\n",
    "    \"\"\"Create a visualization of policy areas ranked by polarization over time.\"\"\"\n",
    "    \n",
    "    # Get all years and policy areas\n",
    "    all_years = sorted(set(y for pa in polarization_metrics.values() for y in pa.keys()))\n",
    "    policy_areas = list(polarization_metrics.keys())\n",
    "    \n",
    "    # Create a matrix of polarization values [policy_areas x years]\n",
    "    polarization_matrix = pd.DataFrame(index=policy_areas, columns=all_years)\n",
    "    \n",
    "    for policy_area in policy_areas:\n",
    "        for year in all_years:\n",
    "            if year in polarization_metrics[policy_area]:\n",
    "                polarization_matrix.loc[policy_area, year] = polarization_metrics[policy_area][year]['avg_distance']\n",
    "    \n",
    "    # Calculate overall polarization for each policy area (average over years)\n",
    "    avg_polarization = polarization_matrix.mean(axis=1).dropna()\n",
    "    \n",
    "    # Sort policy areas by average polarization\n",
    "    sorted_areas = avg_polarization.sort_values(ascending=False)\n",
    "    \n",
    "    # Take top and bottom 10 policy areas\n",
    "    top_areas = sorted_areas.head(10)\n",
    "    bottom_areas = sorted_areas.tail(10)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 14), sharex=True)\n",
    "    \n",
    "    # Plot top 10 most polarized areas\n",
    "    top_areas.plot(kind='barh', ax=axes[0], color='tomato')\n",
    "    axes[0].set_title('Top 10 Most Polarized Policy Areas', fontsize=14)\n",
    "    axes[0].set_xlabel('Average Polarization', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot bottom 10 least polarized areas\n",
    "    bottom_areas.plot(kind='barh', ax=axes[1], color='skyblue')\n",
    "    axes[1].set_title('Top 10 Least Polarized Policy Areas', fontsize=14)\n",
    "    axes[1].set_xlabel('Average Polarization', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/4_policy_area_ranking.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a heatmap showing polarization for each policy area over time\n",
    "    # Select top 15 most interesting areas (with highest variance)\n",
    "    policy_var = polarization_matrix.var(axis=1).dropna()\n",
    "    interesting_areas = policy_var.sort_values(ascending=False).head(15).index.tolist()\n",
    "    \n",
    "    # Create a filtered matrix with just these areas\n",
    "    filtered_matrix = polarization_matrix.loc[interesting_areas].copy()\n",
    "    \n",
    "    # Convert all values to float and replace NaN with a clear indicator for plotting\n",
    "    for col in filtered_matrix.columns:\n",
    "        filtered_matrix[col] = filtered_matrix[col].astype(float)\n",
    "    \n",
    "    # Create heatmap using a manual approach to avoid the dtype error\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create a masked array for the heatmap\n",
    "    masked_data = np.ma.masked_invalid(filtered_matrix.values)\n",
    "    \n",
    "    # Create heatmap manually\n",
    "    im = plt.imshow(masked_data, cmap='RdBu_r', aspect='auto', interpolation='nearest')\n",
    "    \n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar(im, label='Polarization')\n",
    "    \n",
    "    # Set x and y ticks\n",
    "    plt.yticks(range(len(filtered_matrix.index)), filtered_matrix.index)\n",
    "    plt.xticks(range(len(filtered_matrix.columns)), \n",
    "              filtered_matrix.columns, rotation=45, ha='right')\n",
    "    \n",
    "    plt.title('Polarization Trends by Policy Area Over Time', fontsize=14)\n",
    "    plt.ylabel('Policy Area', fontsize=12)\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/5_policy_area_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return sorted_areas, filtered_matrix\n",
    "\n",
    "# Main function to generate all visualizations\n",
    "def generate_all_visualizations(similarity_matrices):\n",
    "    \"\"\"Generate all visualizations for the EPG polarization story.\"\"\"\n",
    "    \n",
    "    # Calculate polarization metrics\n",
    "    polarization_metrics = calculate_polarization_metrics(similarity_matrices)\n",
    "    \n",
    "    # Part 1: Overview Heatmap\n",
    "    print(\"Creating overview heatmap...\")\n",
    "    aggregate_matrix = create_overview_heatmap(similarity_matrices)\n",
    "    \n",
    "    # Part 2: PCA Visualization\n",
    "    print(\"Creating PCA visualization...\")\n",
    "    pca_df = create_pca_visualization(aggregate_matrix)\n",
    "    \n",
    "    # Part 3: Time Series Analysis\n",
    "    print(\"Creating polarization time series...\")\n",
    "    time_series_data, avg_polarization_by_year, interesting_areas = create_polarization_time_series(\n",
    "        similarity_matrices, polarization_metrics\n",
    "    )\n",
    "    \n",
    "    # Part 4: Policy Area Ranking\n",
    "    print(\"Creating policy area ranking...\")\n",
    "    sorted_areas, filtered_matrix = create_policy_area_ranking(\n",
    "        polarization_metrics, avg_polarization_by_year\n",
    "    )\n",
    "    \n",
    "    # Create a comprehensive story document\n",
    "    story_text = \"\"\"\n",
    "# European Parliament Voting Patterns: A Story of Polarization\n",
    "\n",
    "This visual narrative explores how voting patterns in the European Parliament have evolved over time, with a focus on political polarization across different policy areas.\n",
    "\n",
    "## Part 1: The Overview\n",
    "\n",
    "The heatmap provides a broad overview of voting similarities between different European Parliament Groups (EPGs) across all years and policy areas. Bright red areas indicate high similarity (groups voting together), while blue areas show dissimilarity (groups voting against each other).\n",
    "\n",
    "![Overview Heatmap](story_plots/1_overview_heatmap.png)\n",
    "\n",
    "This visualization reveals the fundamental structure of EPG voting patterns. We can observe clear clustering of ideologically similar groups, with a general left-right spectrum visible. The progressive-left groups (GUE/NGL, Greens) show high internal similarity, as do the center-right and conservative groups (EPP, ECR). This confirms the expected ideological divisions in the Parliament.\n",
    "\n",
    "## Part 2: EPG Positioning in Two Dimensions\n",
    "\n",
    "Using Principal Component Analysis (PCA), we can visualize the relative positioning of EPGs based on their voting similarities:\n",
    "\n",
    "![PCA Visualization](story_plots/2_pca_visualization.png)\n",
    "\n",
    "The PCA plot reveals how EPGs are positioned relative to each other based on their voting behavior. The first principal component (x-axis) largely corresponds to the traditional left-right political spectrum, while the second component (y-axis) may represent other dimensions of political division such as attitudes toward European integration or social issues.\n",
    "\n",
    "We can observe distinct clusters forming around traditional political families: the progressive left, social democrats, liberals, conservatives, and right-wing groups. The distance between groups in this visualization represents their voting dissimilarity.\n",
    "\n",
    "## Part 3: Polarization Trends Over Time\n",
    "\n",
    "How has polarization in the European Parliament evolved over time? The following time series shows the average distance between EPGs (our polarization metric) for selected policy areas:\n",
    "\n",
    "![Polarization Time Series](story_plots/3_polarization_time_series.png)\n",
    "\n",
    "The black line represents the average polarization across all policy areas, providing a reference point. We can observe that certain policy areas show significantly different polarization trends than others. Some areas have become increasingly polarized over time, while others have shown convergence.\n",
    "\n",
    "Of particular note are the following trends:\n",
    "- The overall polarization (black line) shows a general [increasing/decreasing/stable] trend over the years.\n",
    "- [Specific policy area] shows the most dramatic increase in polarization.\n",
    "- [Specific policy area] has become less polarized over time, suggesting growing consensus.\n",
    "- Periods of [political events, elections, crises] appear to coincide with [increases/decreases] in polarization.\n",
    "\n",
    "## Part 4: Which Policy Areas Are Most Polarizing?\n",
    "\n",
    "Not all policy areas generate the same level of political division. The following visualizations rank policy areas by their average polarization:\n",
    "\n",
    "![Policy Area Ranking](story_plots/4_policy_area_ranking.png)\n",
    "\n",
    "The most polarized policy areas tend to relate to [specific types of policies: e.g., migration, economic policy, social issues], which aligns with our understanding of the most contentious issues in European politics.\n",
    "\n",
    "In contrast, the least polarized areas are generally [specific types of policies: e.g., technical standards, research funding, infrastructure], where there tends to be more technocratic consensus.\n",
    "\n",
    "Finally, we can examine how polarization in different policy areas has evolved over time:\n",
    "\n",
    "![Policy Area Heatmap](story_plots/5_policy_area_heatmap.png)\n",
    "\n",
    "This heatmap reveals interesting patterns of political conflict over time. We can see that:\n",
    "- Some policy areas (e.g., [specific examples]) have become increasingly polarized.\n",
    "- Others (e.g., [specific examples]) show decreasing polarization.\n",
    "- Certain years show higher overall polarization, potentially corresponding to [specific political events or crises].\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Our visual analysis of European Parliament voting patterns reveals a complex landscape of political alignment and polarization. While the traditional left-right spectrum remains evident in voting behavior, polarization varies significantly across policy areas and time periods.\n",
    "\n",
    "The findings suggest that [summarize key insights about polarization trends, their potential causes, and implications for European politics].\n",
    "\n",
    "This analysis provides a foundation for understanding political dynamics in the European Parliament and how they have evolved over time. Future research could explore the causes of polarization in specific policy areas and the impact of external events on parliamentary voting patterns.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the story text\n",
    "    with open('story_plots/polarization_story.md', 'w') as f:\n",
    "        f.write(story_text)\n",
    "    \n",
    "    print(\"All visualizations and story document created in the 'story_plots' folder.\")\n",
    "\n",
    "# You would call generate_all_visualizations(similarity_matrices) to create all plots and story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from bokeh.plotting import figure, save, output_file\n",
    "from bokeh.models import (ColumnDataSource, HoverTool, CustomJS, Slider, Button, \n",
    "                         Range1d, LinearColorMapper, ColorBar, BasicTicker, \n",
    "                         MultiSelect, CheckboxGroup, Legend, LegendItem)\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from bokeh.palettes import RdBu11, Spectral11, Category20, viridis\n",
    "from bokeh.transform import linear_cmap\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Create directory for story plots if it doesn't exist\n",
    "os.makedirs(\"story_plots\", exist_ok=True)\n",
    "\n",
    "# Calculate polarization metrics\n",
    "def calculate_polarization_metrics(similarity_matrices):\n",
    "    \"\"\"Calculate cluster distance as a polarization metric for each year and policy area.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for policy_area in similarity_matrices:\n",
    "        metrics[policy_area] = {}\n",
    "        \n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            sim_matrix = similarity_matrices[policy_area][year]\n",
    "            \n",
    "            # Skip if we don't have enough EPGs\n",
    "            if len(sim_matrix) < 3:\n",
    "                continue\n",
    "                \n",
    "            # Convert similarity to distance\n",
    "            distance_matrix = 1 - sim_matrix\n",
    "            \n",
    "            # Calculate average distance (higher = more polarized)\n",
    "            avg_distance = np.mean(distance_matrix.values[~np.eye(len(distance_matrix), dtype=bool)])\n",
    "            \n",
    "            # Calculate variance of distances (higher = more uneven polarization)\n",
    "            var_distance = np.var(distance_matrix.values[~np.eye(len(distance_matrix), dtype=bool)])\n",
    "            \n",
    "            # Calculate modularity-like measure (higher = more distinct communities)\n",
    "            # This uses variance/mean as a simple proxy for community structure\n",
    "            distances_flat = distance_matrix.values[~np.eye(len(distance_matrix), dtype=bool)].flatten()\n",
    "            if np.mean(distances_flat) > 0:\n",
    "                modularity = np.var(distances_flat) / np.mean(distances_flat)\n",
    "            else:\n",
    "                modularity = 0\n",
    "            \n",
    "            # Calculate cohesion within ideological groups\n",
    "            # Define ideological groups (adapt based on your data)\n",
    "            ideological_groups = {\n",
    "                'Left': ['GUE/NGL', 'LEFT', 'THE LEFT', 'GUE-NGL'], \n",
    "                'Greens': ['G/EFA', 'Greens/EFA', 'The Greens', 'GREENS'],\n",
    "                'Social Democrats': ['S&D', 'SOC', 'PES', 'SD', 'PSE'],\n",
    "                'Liberals': ['ALDE', 'RENEW', 'RE', 'ALDE/ADLE'],\n",
    "                'Christian Democrats': ['EPP', 'PPE', 'PPE-DE', 'EPP-ED'],\n",
    "                'Conservatives': ['ECR', 'UEN'],\n",
    "                'Right-wing': ['ID', 'EFD', 'ENF', 'EFDD', 'IND/DEM', 'ITS'],\n",
    "                'Regionalists': ['EFA', 'REG', 'EDA'],\n",
    "                'Non-affiliated': ['NI']\n",
    "            }\n",
    "            \n",
    "            # Calculate in-group vs out-group distances\n",
    "            in_group_distances = []\n",
    "            out_group_distances = []\n",
    "            \n",
    "            for i, epg_i in enumerate(distance_matrix.index):\n",
    "                for j, epg_j in enumerate(distance_matrix.index):\n",
    "                    if i != j:  # Skip self-comparisons\n",
    "                        distance = distance_matrix.iloc[i, j]\n",
    "                        \n",
    "                        # Check if both EPGs are in the same ideological group\n",
    "                        same_group = False\n",
    "                        for group, members in ideological_groups.items():\n",
    "                            if epg_i in members and epg_j in members:\n",
    "                                same_group = True\n",
    "                                break\n",
    "                        \n",
    "                        if same_group:\n",
    "                            in_group_distances.append(distance)\n",
    "                        else:\n",
    "                            out_group_distances.append(distance)\n",
    "            \n",
    "            # Calculate ideological cohesion (lower = more cohesive within ideological groups)\n",
    "            if in_group_distances and out_group_distances:\n",
    "                ideological_cohesion = np.mean(in_group_distances) / np.mean(out_group_distances)\n",
    "            else:\n",
    "                ideological_cohesion = np.nan\n",
    "            \n",
    "            # Store metrics\n",
    "            metrics[policy_area][year] = {\n",
    "                'avg_distance': avg_distance,\n",
    "                'var_distance': var_distance,\n",
    "                'modularity': modularity,\n",
    "                'ideological_cohesion': ideological_cohesion,\n",
    "                'num_epgs': len(sim_matrix)\n",
    "            }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ----------------------\n",
    "# PART 1: Overview Heatmap with Enhanced Colors\n",
    "# ----------------------\n",
    "\n",
    "def create_overview_heatmap(similarity_matrices):\n",
    "    \"\"\"Create an aggregate heatmap of EPG similarities across all years and policy areas.\"\"\"\n",
    "    \n",
    "    # Get all unique EPGs\n",
    "    all_epgs = set()\n",
    "    for policy_area in similarity_matrices:\n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            matrix = similarity_matrices[policy_area][year]\n",
    "            all_epgs.update(matrix.index)\n",
    "    \n",
    "    all_epgs = sorted(list(all_epgs))\n",
    "    \n",
    "    # Create an aggregate similarity matrix\n",
    "    aggregate_matrix = pd.DataFrame(0.0, index=all_epgs, columns=all_epgs)\n",
    "    count_matrix = pd.DataFrame(0, index=all_epgs, columns=all_epgs)\n",
    "    \n",
    "    # Sum all similarity matrices\n",
    "    for policy_area in similarity_matrices:\n",
    "        for year in similarity_matrices[policy_area]:\n",
    "            matrix = similarity_matrices[policy_area][year]\n",
    "            for i in matrix.index:\n",
    "                for j in matrix.columns:\n",
    "                    aggregate_matrix.loc[i, j] += matrix.loc[i, j]\n",
    "                    count_matrix.loc[i, j] += 1\n",
    "    \n",
    "    # Average the similarities\n",
    "    for i in aggregate_matrix.index:\n",
    "        for j in aggregate_matrix.columns:\n",
    "            if count_matrix.loc[i, j] > 0:\n",
    "                aggregate_matrix.loc[i, j] /= count_matrix.loc[i, j]\n",
    "            else:\n",
    "                # If no data, set to NaN (will be shown as white/missing in heatmap)\n",
    "                aggregate_matrix.loc[i, j] = np.nan\n",
    "    \n",
    "    # Set diagonal to 1 (self-similarity)\n",
    "    for i in aggregate_matrix.index:\n",
    "        aggregate_matrix.loc[i, i] = 1.0\n",
    "    \n",
    "    # Create the heatmap figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Calculate the center point dynamically to enhance color contrast\n",
    "    sim_values = aggregate_matrix.values.flatten()\n",
    "    sim_values = sim_values[~np.isnan(sim_values)]\n",
    "    median_sim = np.median(sim_values)\n",
    "    \n",
    "    # Use a diverging colormap with enhanced contrast\n",
    "    cmap = sns.diverging_palette(220, 20, as_cmap=True)  # Blue to red with more contrast\n",
    "    \n",
    "    # Create the heatmap with enhanced dynamic range\n",
    "    sns.heatmap(aggregate_matrix, cmap=cmap, center=median_sim,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .8},\n",
    "                vmin=max(0, median_sim - 0.3), vmax=min(1, median_sim + 0.3))  # Adjust range for more color variation\n",
    "    \n",
    "    plt.title('Overview: Average EPG Voting Similarity Across All Years and Policy Areas', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/1_overview_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return aggregate_matrix\n",
    "\n",
    "# ----------------------\n",
    "# PART 2: Enhanced PCA Visualization with Correct Political Spectrum\n",
    "# ----------------------\n",
    "\n",
    "def create_pca_visualization(aggregate_matrix):\n",
    "    \"\"\"Create a PCA visualization of EPG positions based on aggregate similarity.\"\"\"\n",
    "    \n",
    "    # Clean the matrix (replace NaN with 0)\n",
    "    clean_matrix = aggregate_matrix.fillna(0)\n",
    "    \n",
    "    # Convert similarity to distance\n",
    "    distance_matrix = 1 - clean_matrix\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(distance_matrix)\n",
    "    \n",
    "    # Create a DataFrame for the results\n",
    "    pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'], index=distance_matrix.index)\n",
    "    \n",
    "    # Organize EPGs into known political groups (comprehensive mapping)\n",
    "    political_spectrum = {\n",
    "        'Left': ['GUE/NGL', 'LEFT', 'THE LEFT', 'GUE-NGL'],\n",
    "        'Greens': ['G/EFA', 'Greens/EFA', 'The Greens', 'GREENS'],\n",
    "        'Social Democrats': ['S&D', 'SOC', 'PES', 'SD', 'PSE'],\n",
    "        'Liberals': ['ALDE', 'RENEW', 'RE', 'ALDE/ADLE'],\n",
    "        'Christian Democrats': ['EPP', 'PPE', 'PPE-DE', 'EPP-ED'],\n",
    "        'Conservatives': ['ECR', 'UEN'],\n",
    "        'Right-wing': ['ID', 'EFD', 'ENF', 'EFDD', 'IND/DEM', 'ITS'],\n",
    "        'Regionalists': ['EFA', 'REG', 'EDA'],\n",
    "        'Non-affiliated': ['NI']\n",
    "    }\n",
    "    \n",
    "    # Define colors for the political spectrum (enhanced palette)\n",
    "    colors = {\n",
    "        'Left': '#d62728',  # Dark red\n",
    "        'Greens': '#2ca02c',  # Green\n",
    "        'Social Democrats': '#ff7f0e',  # Orange\n",
    "        'Liberals': '#ffff00',  # Yellow\n",
    "        'Christian Democrats': '#1f77b4',  # Blue\n",
    "        'Conservatives': '#9467bd',  # Purple\n",
    "        'Right-wing': '#8c564b',  # Brown\n",
    "        'Regionalists': '#e377c2',  # Pink\n",
    "        'Non-affiliated': '#7f7f7f'   # Grey\n",
    "    }\n",
    "    \n",
    "    # Create the PCA visualization\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create a dictionary to store points for legend (to avoid duplicates)\n",
    "    legend_handles = {}\n",
    "    \n",
    "    # Check each EPG and assign to a political group\n",
    "    epg_groups = {}\n",
    "    for epg in pca_df.index:\n",
    "        assigned = False\n",
    "        for group, members in political_spectrum.items():\n",
    "            if any(member.lower() in epg.lower() or epg.lower() in member.lower() for member in members):\n",
    "                epg_groups[epg] = group\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            # Try a more flexible matching for any remaining groups\n",
    "            for group, members in political_spectrum.items():\n",
    "                if any(member.split('/')[0] in epg for member in members if '/' in member):\n",
    "                    epg_groups[epg] = group\n",
    "                    assigned = True\n",
    "                    break\n",
    "        if not assigned:\n",
    "            # Last resort: check for common abbreviations\n",
    "            if 'GUE' in epg or 'LEFT' in epg.upper():\n",
    "                epg_groups[epg] = 'Left'\n",
    "            elif 'GREEN' in epg.upper() or 'G/E' in epg:\n",
    "                epg_groups[epg] = 'Greens'\n",
    "            elif 'S&D' in epg or 'SOC' in epg.upper() or 'SD' in epg.upper():\n",
    "                epg_groups[epg] = 'Social Democrats'\n",
    "            elif 'ALDE' in epg or 'LIB' in epg.upper() or 'RENEW' in epg.upper():\n",
    "                epg_groups[epg] = 'Liberals'\n",
    "            elif 'EPP' in epg or 'PPE' in epg:\n",
    "                epg_groups[epg] = 'Christian Democrats'\n",
    "            elif 'ECR' in epg:\n",
    "                epg_groups[epg] = 'Conservatives'\n",
    "            elif 'EFD' in epg or 'ID' in epg or 'ENF' in epg:\n",
    "                epg_groups[epg] = 'Right-wing'\n",
    "            elif 'REG' in epg.upper() or 'EFA' in epg:\n",
    "                epg_groups[epg] = 'Regionalists'\n",
    "            elif 'NI' in epg:\n",
    "                epg_groups[epg] = 'Non-affiliated'\n",
    "            else:\n",
    "                # If still can't determine, just print a warning and set to 'Other'\n",
    "                print(f\"Warning: Could not assign {epg} to a political group\")\n",
    "                epg_groups[epg] = 'Other'\n",
    "    \n",
    "    # Plot each EPG\n",
    "    for epg in pca_df.index:\n",
    "        group = epg_groups.get(epg, 'Other')\n",
    "        color = colors.get(group, 'gray')\n",
    "        \n",
    "        # Plot the point\n",
    "        plt.scatter(pca_df.loc[epg, 'PC1'], pca_df.loc[epg, 'PC2'], \n",
    "                   color=color, s=120, alpha=0.8, edgecolors='black')\n",
    "        \n",
    "        # Add text label for the EPG\n",
    "        plt.text(pca_df.loc[epg, 'PC1']+0.02, pca_df.loc[epg, 'PC2']+0.02, \n",
    "                epg, fontsize=12, weight='bold')\n",
    "        \n",
    "        # Add to legend handles\n",
    "        if group not in legend_handles:\n",
    "            legend_handles[group] = plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                             markerfacecolor=color, markersize=12, \n",
    "                                             label=group)\n",
    "    \n",
    "    # Add a legend with political groups\n",
    "    plt.legend(handles=list(legend_handles.values()), \n",
    "              title='Political Groups', fontsize=12, \n",
    "              title_fontsize=14, loc='best')\n",
    "    \n",
    "    # Add labels and title\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    plt.xlabel(f'Principal Component 1 ({explained_var[0]:.2%} variance)', fontsize=14)\n",
    "    plt.ylabel(f'Principal Component 2 ({explained_var[1]:.2%} variance)', fontsize=14)\n",
    "    plt.title('PCA: European Parliament Groups Positioned by Voting Patterns', fontsize=16)\n",
    "    \n",
    "    # Add grid lines and enhance visualization\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add horizontal and vertical lines at origin for reference\n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/2_pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return pca_df\n",
    "\n",
    "# ----------------------\n",
    "# PART 3: Interactive Time Series with Multiple Selection\n",
    "# ----------------------\n",
    "\n",
    "def create_interactive_polarization_time_series(similarity_matrices, polarization_metrics):\n",
    "    \"\"\"Create interactive time series plots of polarization metrics with Bokeh.\"\"\"\n",
    "    \n",
    "    # Create a time series of metrics for each policy area\n",
    "    time_series_data = {}\n",
    "    \n",
    "    for policy_area in polarization_metrics:\n",
    "        years = sorted(polarization_metrics[policy_area].keys())\n",
    "        \n",
    "        avg_distances = [polarization_metrics[policy_area][year]['avg_distance'] \n",
    "                        if year in polarization_metrics[policy_area] else None \n",
    "                        for year in years]\n",
    "        \n",
    "        var_distances = [polarization_metrics[policy_area][year]['var_distance'] \n",
    "                        if year in polarization_metrics[policy_area] else None \n",
    "                        for year in years]\n",
    "        \n",
    "        modularity = [polarization_metrics[policy_area][year]['modularity'] \n",
    "                     if year in polarization_metrics[policy_area] else None \n",
    "                     for year in years]\n",
    "        \n",
    "        if 'ideological_cohesion' in next(iter(polarization_metrics[policy_area].values()), {}):\n",
    "            cohesion = [polarization_metrics[policy_area][year]['ideological_cohesion'] \n",
    "                      if year in polarization_metrics[policy_area] and not np.isnan(polarization_metrics[policy_area][year]['ideological_cohesion']) \n",
    "                      else None \n",
    "                      for year in years]\n",
    "        else:\n",
    "            cohesion = [None] * len(years)\n",
    "        \n",
    "        num_epgs = [polarization_metrics[policy_area][year]['num_epgs'] \n",
    "                   if year in polarization_metrics[policy_area] else None \n",
    "                   for year in years]\n",
    "        \n",
    "        time_series_data[policy_area] = {\n",
    "            'years': years,\n",
    "            'avg_distance': avg_distances,\n",
    "            'var_distance': var_distances,\n",
    "            'modularity': modularity,\n",
    "            'cohesion': cohesion,\n",
    "            'num_epgs': num_epgs\n",
    "        }\n",
    "    \n",
    "    # Filter out policy areas with too little data\n",
    "    filtered_policy_areas = {}\n",
    "    for policy_area, data in time_series_data.items():\n",
    "        valid_years = [i for i, d in enumerate(data['avg_distance']) if d is not None]\n",
    "        if len(valid_years) >= 5:  # At least 5 years of data\n",
    "            filtered_policy_areas[policy_area] = {\n",
    "                'years': [data['years'][i] for i in valid_years],\n",
    "                'avg_distance': [data['avg_distance'][i] for i in valid_years],\n",
    "                'var_distance': [data['var_distance'][i] for i in valid_years],\n",
    "                'modularity': [data['modularity'][i] for i in valid_years] if any(data['modularity']) else None,\n",
    "                'cohesion': [data['cohesion'][i] for i in valid_years] if any(data['cohesion']) else None,\n",
    "                'num_epgs': [data['num_epgs'][i] for i in valid_years]\n",
    "            }\n",
    "    \n",
    "    # Calculate average polarization across all policy areas by year\n",
    "    all_years = set()\n",
    "    for policy_area in polarization_metrics:\n",
    "        all_years.update(polarization_metrics[policy_area].keys())\n",
    "    all_years = sorted(all_years)\n",
    "    \n",
    "    avg_polarization_by_year = {}\n",
    "    for year in all_years:\n",
    "        values = []\n",
    "        for policy_area in polarization_metrics:\n",
    "            if year in polarization_metrics[policy_area]:\n",
    "                values.append(polarization_metrics[policy_area][year]['avg_distance'])\n",
    "        \n",
    "        if values:\n",
    "            avg_polarization_by_year[year] = np.mean(values)\n",
    "    \n",
    "    # Create an interactive Bokeh plot\n",
    "    output_file('story_plots/3_interactive_polarization.html')\n",
    "    \n",
    "    # Setup initial data source for the average across all policy areas\n",
    "    avg_source = ColumnDataSource(data=dict(\n",
    "        years=list(avg_polarization_by_year.keys()),\n",
    "        values=list(avg_polarization_by_year.values()),\n",
    "        policy=['Average Across All Areas'] * len(avg_polarization_by_year)\n",
    "    ))\n",
    "    \n",
    "    # Create the figure\n",
    "    p = figure(width=900, height=600, \n",
    "              title='Polarization Trends Over Time by Policy Area',\n",
    "              x_axis_label='Year', y_axis_label='Polarization (Average Distance)',\n",
    "              tools=\"pan,wheel_zoom,box_zoom,reset,save,hover\")\n",
    "    \n",
    "    # Configure hover tool\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Policy Area\", \"@policy\"),\n",
    "        (\"Year\", \"@years\"),\n",
    "        (\"Polarization\", \"@values{0.000}\")\n",
    "    ]\n",
    "    \n",
    "    # Plot the average line\n",
    "    avg_line = p.line('years', 'values', source=avg_source, line_width=3, \n",
    "                     color='black', alpha=0.8, legend_label=\"Average Across All Areas\")\n",
    "    avg_circle = p.circle('years', 'values', source=avg_source, size=8, \n",
    "                         color='black', alpha=0.8)\n",
    "    \n",
    "    # Create multi select widget for policy areas\n",
    "    sorted_areas = sorted(filtered_policy_areas.keys())\n",
    "    \n",
    "    # Select top 5 most varying policy areas as default selected\n",
    "    policy_variance = []\n",
    "    for policy in sorted_areas:\n",
    "        data = filtered_policy_areas[policy]\n",
    "        if len(data['avg_distance']) > 0:\n",
    "            policy_variance.append((policy, np.var(data['avg_distance'])))\n",
    "    \n",
    "    policy_variance.sort(key=lambda x: x[1], reverse=True)\n",
    "    default_selected = [p[0] for p in policy_variance[:5]]\n",
    "    \n",
    "    # Create a mapping of colors for each policy area\n",
    "    color_palette = Category20[20]\n",
    "    policy_colors = {policy: color_palette[i % 20] for i, policy in enumerate(sorted_areas)}\n",
    "    \n",
    "    # Create the multi-select widget\n",
    "    policy_select = MultiSelect(title=\"Select Policy Areas to Compare:\",\n",
    "                              options=sorted_areas,\n",
    "                              value=default_selected,\n",
    "                              height=300,\n",
    "                              width=300)\n",
    "    \n",
    "    # Create data sources for each policy area (initially empty)\n",
    "    policy_sources = {}\n",
    "    policy_lines = {}\n",
    "    policy_circles = {}\n",
    "    \n",
    "    for policy in sorted_areas:\n",
    "        data = filtered_policy_areas[policy]\n",
    "        \n",
    "        # Create source\n",
    "        policy_sources[policy] = ColumnDataSource(data=dict(\n",
    "            years=data['years'],\n",
    "            values=data['avg_distance'],\n",
    "            policy=[policy] * len(data['years']),\n",
    "            visible=[policy in default_selected] * len(data['years'])\n",
    "        ))\n",
    "        \n",
    "        # Create line and circle, set initial visibility\n",
    "        visible = policy in default_selected\n",
    "        \n",
    "        policy_lines[policy] = p.line('years', 'values', source=policy_sources[policy],\n",
    "                                    line_width=2, color=policy_colors[policy],\n",
    "                                    alpha=0.8 if visible else 0,\n",
    "                                    legend_label=policy if visible else \"\")\n",
    "        \n",
    "        policy_circles[policy] = p.circle('years', 'values', source=policy_sources[policy],\n",
    "                                        size=6, color=policy_colors[policy],\n",
    "                                        alpha=0.8 if visible else 0)\n",
    "    \n",
    "    # Add legend\n",
    "    p.legend.location = \"top_left\"\n",
    "    p.legend.click_policy = \"hide\"\n",
    "    \n",
    "    # Create a callback for MultiSelect widget\n",
    "    callback = CustomJS(args=dict(\n",
    "        policy_sources=policy_sources,\n",
    "        policy_lines=policy_lines,\n",
    "        policy_circles=policy_circles,\n",
    "        policy_colors=policy_colors,\n",
    "        p=p), code=\"\"\"\n",
    "        // Get selected policies\n",
    "        const selected_policies = cb_obj.value;\n",
    "        \n",
    "        // Update each policy line and circle visibility\n",
    "        for (const policy in policy_sources) {\n",
    "            const is_selected = selected_policies.includes(policy);\n",
    "            const alpha = is_selected ? 0.8 : 0;\n",
    "            \n",
    "            // Update alpha for lines and circles\n",
    "            policy_lines[policy].glyph.line_alpha = alpha;\n",
    "            policy_circles[policy].glyph.fill_alpha = alpha;\n",
    "            policy_circles[policy].glyph.line_alpha = alpha;\n",
    "            \n",
    "            // Update legend (this doesn't work perfectly in Bokeh callbacks)\n",
    "            if (is_selected) {\n",
    "                policy_lines[policy].legend_label = policy;\n",
    "            } else {\n",
    "                policy_lines[policy].legend_label = \"\";\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // This will trigger a redraw\n",
    "        for (const policy in policy_sources) {\n",
    "            policy_sources[policy].change.emit();\n",
    "        }\n",
    "    \"\"\")\n",
    "    \n",
    "    # Attach callback to widget\n",
    "    policy_select.js_on_change('value', callback)\n",
    "    \n",
    "    # Layout\n",
    "    layout = row(\n",
    "        policy_select,\n",
    "        p\n",
    "    )\n",
    "    \n",
    "    # Save to file\n",
    "    save(layout)\n",
    "    \n",
    "    # Also create a static version for the story\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot average line\n",
    "    years = list(avg_polarization_by_year.keys())\n",
    "    values = list(avg_polarization_by_year.values())\n",
    "    plt.plot(years, values, 'o-', color='black', linewidth=2.5, label='Average Across All Areas')\n",
    "    \n",
    "    # Plot a few interesting policy areas\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "    for i, policy in enumerate(default_selected[:5]):\n",
    "        data = filtered_policy_areas[policy]\n",
    "        plt.plot(data['years'], data['avg_distance'], 'o-', \n",
    "                color=colors[i], linewidth=1.5, label=policy)\n",
    "    \n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Polarization (Average Distance)', fontsize=12)\n",
    "    plt.title('Polarization Trends Over Time by Policy Area', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title='Policy Area', fontsize=10)\n",
    "    \n",
    "    # Save the static figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/3_polarization_time_series.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return filtered_policy_areas, avg_polarization_by_year\n",
    "\n",
    "# ----------------------\n",
    "# PART 4: Policy Area Ranking (Keep Same)\n",
    "# ----------------------\n",
    "\n",
    "def create_policy_area_ranking(polarization_metrics, avg_polarization_by_year):\n",
    "    \"\"\"Create a visualization of policy areas ranked by polarization over time.\"\"\"\n",
    "    \n",
    "    # Get all years and policy areas\n",
    "    all_years = sorted(set(y for pa in polarization_metrics.values() for y in pa.keys()))\n",
    "    policy_areas = list(polarization_metrics.keys())\n",
    "    \n",
    "    # Create a matrix of polarization values [policy_areas x years]\n",
    "    polarization_matrix = pd.DataFrame(index=policy_areas, columns=all_years)\n",
    "    \n",
    "    for policy_area in policy_areas:\n",
    "        for year in all_years:\n",
    "            if year in polarization_metrics[policy_area]:\n",
    "                polarization_matrix.loc[policy_area, year] = polarization_metrics[policy_area][year]['avg_distance']\n",
    "    \n",
    "    # Calculate overall polarization for each policy area (average over years)\n",
    "    avg_polarization = polarization_matrix.mean(axis=1).dropna()\n",
    "    \n",
    "    # Sort policy areas by average polarization\n",
    "    sorted_areas = avg_polarization.sort_values(ascending=False)\n",
    "    \n",
    "    # Take top and bottom 10 policy areas\n",
    "    top_areas = sorted_areas.head(10)\n",
    "    bottom_areas = sorted_areas.tail(10)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 14), sharex=True)\n",
    "    \n",
    "    # Plot top 10 most polarized areas\n",
    "    top_areas.plot(kind='barh', ax=axes[0], color='tomato')\n",
    "    axes[0].set_title('Top 10 Most Polarized Policy Areas', fontsize=14)\n",
    "    axes[0].set_xlabel('Average Polarization', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot bottom 10 least polarized areas\n",
    "    bottom_areas.plot(kind='barh', ax=axes[1], color='skyblue')\n",
    "    axes[1].set_title('Top 10 Least Polarized Policy Areas', fontsize=14)\n",
    "    axes[1].set_xlabel('Average Polarization', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/4_policy_area_ranking.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return sorted_areas, polarization_matrix\n",
    "\n",
    "# ----------------------\n",
    "# PART 5: Polarization Trends Visualization (Fixed)\n",
    "# ----------------------\n",
    "\n",
    "def create_polarization_patterns_visualization(polarization_metrics):\n",
    "    \"\"\"Create visualizations of polarization patterns showing clear trends over time.\"\"\"\n",
    "    \n",
    "    # Extract trends in polarization over time for each policy area\n",
    "    policy_trends = {}\n",
    "    \n",
    "    for policy in polarization_metrics:\n",
    "        years = sorted(polarization_metrics[policy].keys())\n",
    "        if len(years) >= 5:  # Only consider policies with enough data points\n",
    "            values = [polarization_metrics[policy][year]['avg_distance'] for year in years]\n",
    "            \n",
    "            # Calculate linear trend\n",
    "            if len(years) > 1:\n",
    "                try:\n",
    "                    slope, intercept, r_value, p_value, std_err = linregress(years, values)\n",
    "                    policy_trends[policy] = {\n",
    "                        'slope': slope,\n",
    "                        'r_value': r_value,\n",
    "                        'p_value': p_value,\n",
    "                        'years': years,\n",
    "                        'values': values\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating trend for {policy}: {e}\")\n",
    "    \n",
    "    # Sort policies by trend strength (descending by absolute slope)\n",
    "    sorted_policies = sorted(policy_trends.keys(), \n",
    "                            key=lambda p: abs(policy_trends[p]['slope']), \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Select top 5 increasing and top 5 decreasing trends\n",
    "    increasing = [p for p in sorted_policies if policy_trends[p]['slope'] > 0][:5]\n",
    "    decreasing = [p for p in sorted_policies if policy_trends[p]['slope'] < 0][:5]\n",
    "    \n",
    "    # Create a figure showing diverging trends\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot increasing trends\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i, policy in enumerate(increasing):\n",
    "        data = policy_trends[policy]\n",
    "        plt.plot(data['years'], data['values'], 'o-', \n",
    "                label=f\"{policy} (r={data['r_value']:.2f})\")\n",
    "    \n",
    "    plt.title('Policy Areas with Increasing Polarization', fontsize=14)\n",
    "    plt.ylabel('Polarization', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Plot decreasing trends\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i, policy in enumerate(decreasing):\n",
    "        data = policy_trends[policy]\n",
    "        plt.plot(data['years'], data['values'], 'o-', \n",
    "                label=f\"{policy} (r={data['r_value']:.2f})\")\n",
    "    \n",
    "    plt.title('Policy Areas with Decreasing Polarization', fontsize=14)\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Polarization', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/5_polarization_trends.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a second visualization: distribution of policy areas by trend\n",
    "    slopes = [policy_trends[p]['slope'] for p in policy_trends]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(slopes, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    plt.axvline(x=0, color='r', linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('Polarization Trend (Slope)', fontsize=12)\n",
    "    plt.ylabel('Number of Policy Areas', fontsize=12)\n",
    "    plt.title('Distribution of Polarization Trends Across Policy Areas', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add annotations\n",
    "    mean_slope = np.mean(slopes)\n",
    "    plt.axvline(x=mean_slope, color='g', linestyle='-', alpha=0.7)\n",
    "    plt.text(mean_slope+0.001, plt.gca().get_ylim()[1]*0.9, \n",
    "            f'Mean: {mean_slope:.4f}', \n",
    "            color='g', fontsize=12)\n",
    "    \n",
    "    # Count increasing vs decreasing\n",
    "    n_increasing = sum(s > 0 for s in slopes)\n",
    "    n_decreasing = sum(s < 0 for s in slopes)\n",
    "    percent_increasing = (n_increasing / len(slopes)) * 100\n",
    "    \n",
    "    plt.text(0.05, 0.95, f'Increasing: {n_increasing} ({percent_increasing:.1f}%)\\nDecreasing: {n_decreasing} ({100-percent_increasing:.1f}%)', \n",
    "            transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/6_trend_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return policy_trends\n",
    "\n",
    "# ----------------------\n",
    "# PART 6: Interesting Metrics Visualization\n",
    "# ----------------------\n",
    "\n",
    "def create_interesting_metrics_visualization(polarization_metrics):\n",
    "    \"\"\"Create visualizations with interesting new metrics about political dynamics.\"\"\"\n",
    "    \n",
    "    # Create time series for the ideological cohesion metric\n",
    "    all_years = sorted(set(y for pa in polarization_metrics.values() for y in pa.keys()))\n",
    "    \n",
    "    # Get cohesion values for each policy area and year\n",
    "    cohesion_data = {}\n",
    "    for policy_area in polarization_metrics:\n",
    "        cohesion_data[policy_area] = {}\n",
    "        for year in all_years:\n",
    "            if year in polarization_metrics[policy_area] and 'ideological_cohesion' in polarization_metrics[policy_area][year]:\n",
    "                cohesion = polarization_metrics[policy_area][year]['ideological_cohesion']\n",
    "                if not np.isnan(cohesion):\n",
    "                    cohesion_data[policy_area][year] = cohesion\n",
    "    \n",
    "    # Find policy areas with sufficient data\n",
    "    policy_with_data = {p: years for p, years in cohesion_data.items() if len(years) >= 5}\n",
    "    \n",
    "    if not policy_with_data:\n",
    "        # If ideological cohesion data isn't available, return from the trends function\n",
    "        return None\n",
    "    \n",
    "    # Calculate average cohesion across all policy areas\n",
    "    avg_cohesion = {}\n",
    "    for year in all_years:\n",
    "        values = [cohesion_data[p][year] for p in cohesion_data if year in cohesion_data[p]]\n",
    "        if values:\n",
    "            avg_cohesion[year] = np.mean(values)\n",
    "    \n",
    "    # Calculate variance in cohesion across policy areas\n",
    "    policy_cohesion_variance = {}\n",
    "    for policy in policy_with_data:\n",
    "        values = list(cohesion_data[policy].values())\n",
    "        if values:\n",
    "            policy_cohesion_variance[policy] = np.var(values)\n",
    "    \n",
    "    # Select top 5 policy areas with highest variance in cohesion\n",
    "    top_varying = sorted(policy_cohesion_variance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # Create a figure for ideological cohesion over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot average cohesion\n",
    "    years = sorted(avg_cohesion.keys())\n",
    "    values = [avg_cohesion[year] for year in years]\n",
    "    plt.plot(years, values, 'o-', color='black', linewidth=2.5, \n",
    "            label='Average Across All Areas')\n",
    "    \n",
    "    # Plot top 5 policy areas with highest variance\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "    for i, (policy, _) in enumerate(top_varying):\n",
    "        policy_years = sorted(cohesion_data[policy].keys())\n",
    "        policy_values = [cohesion_data[policy][year] for year in policy_years]\n",
    "        plt.plot(policy_years, policy_values, 'o-', color=colors[i], \n",
    "                linewidth=1.5, label=policy)\n",
    "    \n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Ideological Cohesion (Lower = Higher In-Group Cohesion)', fontsize=12)\n",
    "    plt.title('Ideological Group Cohesion Over Time by Policy Area', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title='Policy Area', fontsize=10)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('story_plots/7_ideological_cohesion.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a second visualization: Scatter plot of modularity vs average distance\n",
    "    # This shows the relationship between overall polarization and community structure\n",
    "    \n",
    "    scatter_data = []\n",
    "    for policy in polarization_metrics:\n",
    "        for year in polarization_metrics[policy]:\n",
    "            metrics = polarization_metrics[policy][year]\n",
    "            if 'modularity' in metrics and 'avg_distance' in metrics:\n",
    "                scatter_data.append({\n",
    "                    'policy': policy,\n",
    "                    'year': year,\n",
    "                    'modularity': metrics['modularity'],\n",
    "                    'avg_distance': metrics['avg_distance']\n",
    "                })\n",
    "    \n",
    "    if scatter_data:\n",
    "        scatter_df = pd.DataFrame(scatter_data)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create categories based on policy area type (simplified example - adapt to your data)\n",
    "        policy_categories = {}\n",
    "        for policy in polarization_metrics:\n",
    "            if 'budget' in policy.lower() or 'economic' in policy.lower() or 'tax' in policy.lower() or 'finance' in policy.lower():\n",
    "                policy_categories[policy] = 'Economic'\n",
    "            elif 'social' in policy.lower() or 'health' in policy.lower() or 'education' in policy.lower():\n",
    "                policy_categories[policy] = 'Social'\n",
    "            elif 'environment' in policy.lower() or 'climate' in policy.lower() or 'energy' in policy.lower():\n",
    "                policy_categories[policy] = 'Environment'\n",
    "            elif 'security' in policy.lower() or 'defense' in policy.lower() or 'military' in policy.lower():\n",
    "                policy_categories[policy] = 'Security & Defense'\n",
    "            elif 'migra' in policy.lower() or 'asylum' in policy.lower() or 'immigra' in policy.lower():\n",
    "                policy_categories[policy] = 'Migration'\n",
    "            elif 'agriculture' in policy.lower() or 'fish' in policy.lower() or 'food' in policy.lower():\n",
    "                policy_categories[policy] = 'Agriculture'\n",
    "            elif 'institu' in policy.lower() or 'constitu' in policy.lower() or 'governance' in policy.lower():\n",
    "                policy_categories[policy] = 'Institutional'\n",
    "            else:\n",
    "                policy_categories[policy] = 'Other'\n",
    "                \n",
    "        # Add category to DataFrame\n",
    "        scatter_df['category'] = scatter_df['policy'].map(policy_categories)\n",
    "        \n",
    "        # Define colors for categories\n",
    "        category_colors = {\n",
    "            'Economic': '#1f77b4',  # Blue\n",
    "            'Social': '#ff7f0e',    # Orange\n",
    "            'Environment': '#2ca02c',  # Green\n",
    "            'Security & Defense': '#d62728',  # Red\n",
    "            'Migration': '#9467bd',  # Purple\n",
    "            'Agriculture': '#8c564b',  # Brown\n",
    "            'Institutional': '#e377c2',  # Pink\n",
    "            'Other': '#7f7f7f'  # Gray\n",
    "        }\n",
    "        \n",
    "        # Plot each category with a different color\n",
    "        for category, color in category_colors.items():\n",
    "            subset = scatter_df[scatter_df['category'] == category]\n",
    "            if not subset.empty:\n",
    "                plt.scatter(subset['avg_distance'], subset['modularity'], \n",
    "                           color=color, alpha=0.7, s=60, label=category)\n",
    "        \n",
    "        # Add regression line\n",
    "        from scipy.stats import linregress\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(\n",
    "            scatter_df['avg_distance'], scatter_df['modularity']\n",
    "        )\n",
    "        x_line = np.linspace(scatter_df['avg_distance'].min(), scatter_df['avg_distance'].max(), 100)\n",
    "        y_line = slope * x_line + intercept\n",
    "        plt.plot(x_line, y_line, 'k--', alpha=0.5)\n",
    "        \n",
    "        # Add correlation coefficient to the plot\n",
    "        plt.text(0.05, 0.95, f'Correlation: {r_value:.2f}', transform=plt.gca().transAxes, \n",
    "                fontsize=12, verticalalignment='top')\n",
    "        \n",
    "        plt.xlabel('Polarization (Average Distance)', fontsize=12)\n",
    "        plt.ylabel('Modularity (Higher = More Distinct Communities)', fontsize=12)\n",
    "        plt.title('Relationship Between Polarization and Community Structure', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(title='Policy Category', fontsize=10)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('story_plots/8_polarization_structure.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    return cohesion_data, scatter_df if scatter_data else None\n",
    "\n",
    "# Main function to generate all visualizations\n",
    "def generate_all_visualizations(similarity_matrices):\n",
    "    \"\"\"Generate all visualizations for the EPG polarization story.\"\"\"\n",
    "    \n",
    "    # Calculate polarization metrics\n",
    "    polarization_metrics = calculate_polarization_metrics(similarity_matrices)\n",
    "    \n",
    "    # Part 1: Overview Heatmap with Enhanced Colors\n",
    "    print(\"Creating overview heatmap with enhanced colors...\")\n",
    "    aggregate_matrix = create_overview_heatmap(similarity_matrices)\n",
    "    \n",
    "    # Part 2: Enhanced PCA Visualization with Correct Political Spectrum\n",
    "    print(\"Creating enhanced PCA visualization...\")\n",
    "    pca_df = create_pca_visualization(aggregate_matrix)\n",
    "    \n",
    "    # Part 3: Interactive Time Series with Multiple Selection\n",
    "    print(\"Creating interactive polarization time series...\")\n",
    "    filtered_policy_areas, avg_polarization_by_year = create_interactive_polarization_time_series(\n",
    "        similarity_matrices, polarization_metrics\n",
    "    )\n",
    "    \n",
    "    # Part 4: Policy Area Ranking (Keep Same)\n",
    "    print(\"Creating policy area ranking...\")\n",
    "    sorted_areas, polarization_matrix = create_policy_area_ranking(\n",
    "        polarization_metrics, avg_polarization_by_year\n",
    "    )\n",
    "    \n",
    "    # Part 5: Polarization Trends Visualization (Fixed)\n",
    "    print(\"Creating polarization trends visualization...\")\n",
    "    policy_trends = create_polarization_patterns_visualization(polarization_metrics)\n",
    "    \n",
    "    # Part 6: New Interesting Metrics Visualization\n",
    "    print(\"Creating new interesting metrics visualization...\")\n",
    "    additional_metrics = create_interesting_metrics_visualization(polarization_metrics)\n",
    "    \n",
    "    # Create a comprehensive story document\n",
    "    story_text = \"\"\"\n",
    "# European Parliament Voting Patterns: A Story of Polarization\n",
    "\n",
    "This visual narrative explores how voting patterns in the European Parliament have evolved over time, with a focus on political polarization across different policy areas.\n",
    "\n",
    "## Part 1: The Overview\n",
    "\n",
    "The heatmap provides a broad overview of voting similarities between different European Parliament Groups (EPGs) across all years and policy areas. Bright red areas indicate high similarity (groups voting together), while blue areas show dissimilarity (groups voting against each other).\n",
    "\n",
    "![Overview Heatmap](story_plots/1_overview_heatmap.png)\n",
    "\n",
    "This visualization reveals the fundamental structure of EPG voting patterns. We can observe clear clustering of ideologically similar groups, with a general left-right spectrum visible. The progressive-left groups (GUE/NGL, Greens) show high internal similarity, as do the center-right and conservative groups (EPP, ECR). This confirms the expected ideological divisions in the Parliament.\n",
    "\n",
    "## Part 2: EPG Positioning in Two Dimensions\n",
    "\n",
    "Using Principal Component Analysis (PCA), we can visualize the relative positioning of EPGs based on their voting similarities:\n",
    "\n",
    "![PCA Visualization](story_plots/2_pca_visualization.png)\n",
    "\n",
    "The PCA plot reveals how EPGs are positioned relative to each other based on their voting behavior. The first principal component (x-axis) largely corresponds to the traditional left-right political spectrum, while the second component (y-axis) may represent other dimensions of political division such as attitudes toward European integration or social issues.\n",
    "\n",
    "We can observe distinct clusters forming around traditional political families: the progressive left, social democrats, liberals, conservatives, and right-wing groups. The distance between groups in this visualization represents their voting dissimilarity.\n",
    "\n",
    "## Part 3: Polarization Trends Over Time\n",
    "\n",
    "How has polarization in the European Parliament evolved over time? The following time series shows the average distance between EPGs (our polarization metric) for selected policy areas:\n",
    "\n",
    "![Polarization Time Series](story_plots/3_polarization_time_series.png)\n",
    "\n",
    "The black line represents the average polarization across all policy areas, providing a reference point. We can observe that certain policy areas show significantly different polarization trends than others. Some areas have become increasingly polarized over time, while others have shown convergence.\n",
    "\n",
    "For an interactive version of this visualization where you can select specific policy areas to compare, open the HTML file in the story_plots folder.\n",
    "\n",
    "## Part 4: Which Policy Areas Are Most Polarizing?\n",
    "\n",
    "Not all policy areas generate the same level of political division. The following visualizations rank policy areas by their average polarization:\n",
    "\n",
    "![Policy Area Ranking](story_plots/4_policy_area_ranking.png)\n",
    "\n",
    "The most polarized policy areas tend to relate to [specific types of policies: e.g., migration, economic policy, social issues], which aligns with our understanding of the most contentious issues in European politics.\n",
    "\n",
    "In contrast, the least polarized areas are generally [specific types of policies: e.g., technical standards, research funding, infrastructure], where there tends to be more technocratic consensus.\n",
    "\n",
    "## Part 5: Polarization Trends Across Policy Areas\n",
    "\n",
    "Some policy areas are becoming more polarized over time, while others are showing increasing consensus. The following visualizations show the most dramatic trends in both directions:\n",
    "\n",
    "![Polarization Trends](story_plots/5_polarization_trends.png)\n",
    "\n",
    "The top panel shows policy areas that have become increasingly polarized over time, while the bottom panel shows areas where polarization has decreased. This helps us identify which issues are becoming more or less contentious in European politics.\n",
    "\n",
    "We can also look at the overall distribution of trends across all policy areas:\n",
    "\n",
    "![Trend Distribution](story_plots/6_trend_distribution.png)\n",
    "\n",
    "This histogram shows how many policy areas are becoming more polarized versus less polarized. The vertical red line indicates zero change, while the green line shows the mean trend. This gives us a sense of the overall direction of polarization in the European Parliament.\n",
    "\n",
    "## Part 6: Deeper Insights into Political Dynamics\n",
    "\n",
    "Beyond simple polarization, we can explore more complex patterns in parliamentary voting behavior:\n",
    "\n",
    "![Ideological Cohesion](story_plots/7_ideological_cohesion.png)\n",
    "\n",
    "This visualization shows how cohesive ideological groups are in different policy areas over time. Lower values indicate that EPGs within the same ideological family (e.g., left, center-left) vote more similarly to each other than to EPGs from different families.\n",
    "\n",
    "We can also examine the relationship between overall polarization and the formation of distinct voting communities:\n",
    "\n",
    "![Polarization Structure](story_plots/8_polarization_structure.png)\n",
    "\n",
    "This scatter plot reveals how polarization relates to the formation of distinct voting blocs. Each point represents a policy area in a specific year, colored by policy category. The correlation between these metrics tells us whether increased polarization tends to create more distinct voting communities or more fragmented voting patterns.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Our visual analysis of European Parliament voting patterns reveals a complex landscape of political alignment and polarization. While the traditional left-right spectrum remains evident in voting behavior, polarization varies significantly across policy areas and time periods.\n",
    "\n",
    "The findings suggest that [summarize key insights about polarization trends, their potential causes, and implications for European politics].\n",
    "\n",
    "This analysis provides a foundation for understanding political dynamics in the European Parliament and how they have evolved over time. Future research could explore the causes of polarization in specific policy areas and the impact of external events on parliamentary voting patterns.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the story text\n",
    "    with open('story_plots/polarization_story.md', 'w') as f:\n",
    "        f.write(story_text)\n",
    "    \n",
    "    print(\"All visualizations and story document created in the 'story_plots' folder.\")\n",
    "\n",
    "# You would call generate_all_visualizations(similarity_matrices) to create all plots and story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating overview heatmap with enhanced colors...\n",
      "Creating enhanced PCA visualization...\n",
      "Creating interactive polarization time series...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating policy area ranking...\n",
      "Creating polarization trends visualization...\n",
      "Creating new interesting metrics visualization...\n",
      "All visualizations and story document created in the 'story_plots' folder.\n"
     ]
    }
   ],
   "source": [
    "generate_all_visualizations(similarity_matrices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
