{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Our research utilizes a comprehensive dataset of European Parliament voting records. This dataset captures how each Member of the European Parliament (MEP) voted on proposed legislation, along with detailed information about the legislation itself, the MEPs, and their party affiliations.\n",
    "\n",
    "We selected this dataset because of its rich potential for political analysis. Our aim is to examine whether recent trends toward political polarization and right-leaning policies are reflected in voting patterns within the European Parliament.\n",
    "\n",
    "The primary objective of our study is to test our hypothesis that political polarization has increased in contemporary European politics, as potentially evidenced through parliamentary voting behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_name(first_name, last_name):\n",
    "    import unicodedata\n",
    "    \n",
    "    if not isinstance(first_name, str):\n",
    "        first_name = str(first_name) if first_name is not None else \"\"\n",
    "    if not isinstance(last_name, str):\n",
    "        last_name = str(last_name) if last_name is not None else \"\"\n",
    "    \n",
    "    first_name = first_name.lower().strip()\n",
    "    last_name = last_name.lower().strip()\n",
    "    \n",
    "    def normalize_chars(text):\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        return text\n",
    "    \n",
    "    first_name = normalize_chars(first_name)\n",
    "    last_name = normalize_chars(last_name)\n",
    "    \n",
    "    for char in ['-', \"'\", \"`\", \".\", \",\", \"&\", \"'\"]:  # Added apostrophe variants\n",
    "        first_name = first_name.replace(char, ' ')\n",
    "        last_name = last_name.replace(char, ' ')\n",
    "    \n",
    "    while '  ' in first_name:\n",
    "        first_name = first_name.replace('  ', ' ')\n",
    "    while '  ' in last_name:\n",
    "        last_name = last_name.replace('  ', ' ')\n",
    "        \n",
    "    first_name = ' '.join(word.capitalize() for word in first_name.split())\n",
    "    last_name = ' '.join(word.capitalize() for word in last_name.split())\n",
    "    \n",
    "    full_name = f\"{first_name} {last_name}\".strip()\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "  \n",
    "    text = text.lower()\n",
    "    \n",
    "    for char in ['&', ',', '-']:\n",
    "        text = text.replace(char, ' ')\n",
    "    \n",
    "    text = text.replace(' and ', ' ')\n",
    "    \n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    \n",
    "    return text.strip()    \n",
    "\n",
    "def process_ep_voting_data(rcv_files, voted_docs_files):\n",
    "\n",
    "    if len(rcv_files) != len(voted_docs_files):\n",
    "        raise ValueError(\"The lists of RCV files and Voted docs files must have the same length\")\n",
    "     \n",
    "    all_data = []\n",
    "    \n",
    "    for i, (rcv_file, voted_doc_file) in enumerate(zip(rcv_files, voted_docs_files)):\n",
    "        print(f\"Processing files {i+1}/{len(rcv_files)}: {rcv_file} and {voted_doc_file}\")\n",
    "        \n",
    "        if \"EP6\" in rcv_file:\n",
    "            ep_session = \"EP6\"\n",
    "            vote_start_index = 10\n",
    "            rcv_data = pd.read_excel(rcv_file, header=1)\n",
    "        elif \"EP7\" in rcv_file:\n",
    "            ep_session = \"EP7\"\n",
    "            vote_start_index = 9\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP8\" in rcv_file:\n",
    "            ep_session = \"EP8\"\n",
    "            vote_start_index = 9\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        elif \"EP9\" in rcv_file:\n",
    "            ep_session = \"EP9\"\n",
    "            vote_start_index = 10\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "        else:\n",
    "            ep_session = \"Unknown\"\n",
    "            rcv_data = pd.read_excel(rcv_file, sheet_name=0)\n",
    "            print(\"UNKNOWN SESSION\")\n",
    "\n",
    "        rcv_data = rcv_data.dropna(how='all')\n",
    "        \n",
    "        voted_docs = pd.read_excel(voted_doc_file)\n",
    "\n",
    "\n",
    "        # Get vote columns headers (index)\n",
    "        vote_columns = rcv_data.columns[vote_start_index:].tolist()\n",
    "       \n",
    "        votes_df = process_votes_ep(rcv_data, voted_docs, vote_columns, ep_session=ep_session)\n",
    "\n",
    "        print(f\"Should be total length: {len(rcv_data) * len(voted_docs)}\")\n",
    "        print(f\"Got length: {len(votes_df)}\")      \n",
    "\n",
    "        # Add EP session information\n",
    "        votes_df['ep_session'] = ep_session\n",
    "        \n",
    "        # Append to the list of results\n",
    "        all_data.append(votes_df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Perform final cleaning\n",
    "    combined_df = clean_combined_data(combined_df)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def process_votes_ep(rcv_data, voted_docs, vote_columns, ep_session = None):\n",
    "    \"\"\"Process voting data for EP7, EP8, EP9 sessions\"\"\"\n",
    "\n",
    "    total_skipped = 0\n",
    "\n",
    "    if ep_session == 'EP6':\n",
    "        date = 'date'\n",
    "        title = 'title'\n",
    "        policy_area = 'main_policy_name'\n",
    "        vote_id_key = 'euro_act_id'\n",
    "        author = 'author_name'\n",
    "\n",
    "        mep_id_key = 'WebisteEpID'\n",
    "\n",
    "    else:\n",
    "        date = 'Date'\n",
    "        title = 'Title'\n",
    "        policy_area = 'De'\n",
    "        vote_id_key = 'Vote ID'\n",
    "        author = 'Author'\n",
    "\n",
    "        mep_id_key = 'WebisteEpID'\n",
    "\n",
    "        if ep_session == 'EP7':\n",
    "            mep_id_key = 'MEP ID'\n",
    "\n",
    "        if ep_session == 'EP8':\n",
    "            policy_area = \"De/Policy area\"\n",
    "\n",
    "        elif ep_session == 'EP9':\n",
    "            policy_area = 'Policy area'\n",
    "  \n",
    "    \n",
    "    # Create a dictionary to map vote IDs to vote information\n",
    "    vote_info = {}\n",
    "    for _, row in voted_docs.iterrows():\n",
    "\n",
    "        vote_info[str(row[vote_id_key])] = {\n",
    "            'date': row[date],\n",
    "            'title': row[title],\n",
    "            'policy_area': row[policy_area],\n",
    "            'author': author,\n",
    "        }\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each MEP's votes\n",
    "    for _, mep_row in rcv_data.iterrows():\n",
    "        country = mep_row['Country']\n",
    "        party = mep_row['Party']\n",
    "        epg = mep_row['EPG']\n",
    "\n",
    "        first_name = mep_row['Fname']\n",
    "        last_name = mep_row['Lname']\n",
    "        \n",
    "        mep_id = mep_row[mep_id_key]\n",
    "    \n",
    "        # Process each vote for this MEP\n",
    "        for vote_col in vote_columns:\n",
    "            \n",
    "            vote_col = str(vote_col)\n",
    "            vote_code = f'{ep_session}-{vote_col}' \n",
    "            \n",
    "            if vote_col not in vote_info:\n",
    "                total_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                mep_vote = mep_row[str(vote_col)]\n",
    "            except Exception as e:\n",
    "                mep_vote = mep_row[int(vote_col)]\n",
    "            \n",
    "            if mep_vote == 0:\n",
    "                continue\n",
    "                \n",
    "            info = vote_info[vote_col]\n",
    "            \n",
    "            results.append({\n",
    "                'full name': clean_name(first_name, last_name),\n",
    "                'country': country,\n",
    "                'national_party': party,\n",
    "                'epg': epg,\n",
    "                'mep_id': mep_id,\n",
    "                'vote_code': vote_code,\n",
    "                'vote': mep_vote,\n",
    "                'date': info['date'],\n",
    "                'title': info['title'],\n",
    "                'policy_area': clean_text(info['policy_area']),\n",
    "            })\n",
    "    \n",
    "    print(f\"Were not able to match: {total_skipped} votes\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def clean_combined_data(df):\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['policy_area_cleaned'] = df['policy_area'].str.strip().str.lower()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files 1/4: VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx and VoteWatch-EP-voting-data_2004-2022/EP6_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be total length: 5827060\n",
      "Got length: 4759840\n",
      "Processing files 2/4: VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx and VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be total length: 5937733\n",
      "Got length: 5233859\n",
      "Processing files 3/4: VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx and VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\n",
      "Were not able to match: 0 votes\n",
      "Should be total length: 8796216\n",
      "Got length: 7696506\n",
      "Processing files 4/4: VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx and VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markusswegmark/Desktop/Visualization/-socialdata2025-MMC-/.venv/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Were not able to match: 0 votes\n",
      "Should be total length: 10915249\n",
      "Got length: 9520348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "voted_docs_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_Voted docs.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_Voted docs.xlsx\"]\n",
    "rcv_files = [\"VoteWatch-EP-voting-data_2004-2022/EP6_RCVs_2022_06_13.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP7_RCVs_2014_06_19.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP8_RCVs_2019_06_25.xlsx\", \"VoteWatch-EP-voting-data_2004-2022/EP9_RCVs_2022_06_22.xlsx\"]\n",
    "\n",
    "combined_df = process_ep_voting_data(rcv_files, voted_docs_files)\n",
    "\n",
    "# Save the combined dataframe\n",
    "output_file = \"ep_voting_data_combined.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers:\n",
      "['full name', 'country', 'national_party', 'epg', 'mep_id', 'vote_code', 'vote', 'date', 'title', 'policy_area', 'ep_session', 'year', 'month', 'policy_area_cleaned']\n",
      "\n",
      "Total number of headers: 14\n"
     ]
    }
   ],
   "source": [
    "# Get all column headers as a list\n",
    "headers_list = combined_df.columns.tolist()\n",
    "\n",
    "# Print the list of headers\n",
    "print(\"Column headers:\")\n",
    "print(headers_list)\n",
    "\n",
    "# Print the total number of headers\n",
    "print(f\"\\nTotal number of headers: {len(headers_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ep_voting_data_combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full name', 'country', 'national_party', 'epg', 'mep_id', 'vote_code', 'vote', 'date', 'title', 'policy_area', 'ep_session', 'year', 'month', 'policy_area_cleaned']\n",
      "[1. 5. 2. 3. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "headers_list = list(df.columns)\n",
    "print(headers_list)\n",
    "print(df['vote'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def rice_index(yes, no, abstain):\n",
    "    return abs(yes - no)/(yes + no + abstain)\n",
    "\n",
    "def calculate_similarity(votes_epg1, votes_epg2):\n",
    "    # Get vote counts for each EPG\n",
    "    yes1 = votes_epg1.get(1, 0)\n",
    "    no1 = votes_epg1.get(2, 0)\n",
    "    abstain1 = votes_epg1.get(3, 0)\n",
    "    \n",
    "    yes2 = votes_epg2.get(1, 0)\n",
    "    no2 = votes_epg2.get(2, 0)\n",
    "    abstain2 = votes_epg2.get(3, 0)\n",
    "    \n",
    "    # Calculate total votes for each EPG\n",
    "    total1 = yes1 + no1 + abstain1\n",
    "    total2 = yes2 + no2 + abstain2\n",
    "    \n",
    "    if total1 == 0 or total2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate percentage of each vote type\n",
    "    yes_pct1 = yes1 / total1 if total1 > 0 else 0\n",
    "    no_pct1 = no1 / total1 if total1 > 0 else 0\n",
    "    abstain_pct1 = abstain1 / total1 if total1 > 0 else 0\n",
    "    \n",
    "    yes_pct2 = yes2 / total2 if total2 > 0 else 0\n",
    "    no_pct2 = no2 / total2 if total2 > 0 else 0\n",
    "    abstain_pct2 = abstain2 / total2 if total2 > 0 else 0\n",
    "    \n",
    "    # Calculate similarity (1 - Euclidean distance between vote percentages)\n",
    "    distance = np.sqrt((yes_pct1 - yes_pct2)**2 + (no_pct1 - no_pct2)**2 + (abstain_pct1 - abstain_pct2)**2)\n",
    "    similarity = 1 - (distance / np.sqrt(2))  # Normalized between 0 and 1\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "\n",
    "df_year = df.groupby(['year', 'policy_area'])\n",
    "epgs = sorted(df['epg'].unique())\n",
    "\n",
    "similarity_matrices = {}\n",
    "\n",
    "for name, group in df_year:\n",
    "    year, policy_area = name \n",
    "    year = int(year)\n",
    "\n",
    "    sim_matrix = pd.DataFrame(index=epgs, columns=epgs)\n",
    "\n",
    "    # Calculate similarities between all EPG pairs\n",
    "    for epg1, epg2 in combinations(epgs, 2):\n",
    "        similarity = calculate_similarity(df[df['epg'] == epg1]['vote'].value_counts(), df[df['epg'] == epg2]['vote'].value_counts())\n",
    "        sim_matrix.loc[epg1, epg2] = similarity\n",
    "        sim_matrix.loc[epg2, epg1] = similarity  # Matrix is symmetric\n",
    "\n",
    "    # Set diagonal to 1 (self-similarity)\n",
    "    for epg in epgs:\n",
    "        sim_matrix.loc[epg, epg] = 1.0\n",
    "            \n",
    "    # Store the matrix\n",
    "    matrix_key = (year, policy_area)\n",
    "    similarity_matrices[matrix_key] = sim_matrix.fillna(0)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "# Function to calculate Rice cohesion index\n",
    "def rice_index(yes, no, abstain):\n",
    "    if (yes + no + abstain) == 0:\n",
    "        return 0\n",
    "    return abs(yes - no) / (yes + no + abstain)\n",
    "\n",
    "# Function to calculate similarity between two EPGs based on their voting patterns\n",
    "def calculate_similarity(votes_epg1, votes_epg2):\n",
    "    # Get vote counts for each EPG\n",
    "    yes1 = votes_epg1.get(1, 0)\n",
    "    no1 = votes_epg1.get(2, 0)\n",
    "    abstain1 = votes_epg1.get(3, 0)\n",
    "    \n",
    "    yes2 = votes_epg2.get(1, 0)\n",
    "    no2 = votes_epg2.get(2, 0)\n",
    "    abstain2 = votes_epg2.get(3, 0)\n",
    "    \n",
    "    # Calculate total votes for each EPG\n",
    "    total1 = yes1 + no1 + abstain1\n",
    "    total2 = yes2 + no2 + abstain2\n",
    "    \n",
    "    if total1 == 0 or total2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate percentage of each vote type\n",
    "    yes_pct1 = yes1 / total1 if total1 > 0 else 0\n",
    "    no_pct1 = no1 / total1 if total1 > 0 else 0\n",
    "    abstain_pct1 = abstain1 / total1 if total1 > 0 else 0\n",
    "    \n",
    "    yes_pct2 = yes2 / total2 if total2 > 0 else 0\n",
    "    no_pct2 = no2 / total2 if total2 > 0 else 0\n",
    "    abstain_pct2 = abstain2 / total2 if total2 > 0 else 0\n",
    "    \n",
    "    # Calculate similarity (1 - Euclidean distance between vote percentages)\n",
    "    distance = np.sqrt((yes_pct1 - yes_pct2)**2 + (no_pct1 - no_pct2)**2 + (abstain_pct1 - abstain_pct2)**2)\n",
    "    similarity = 1 - (distance / np.sqrt(2))  # Normalized between 0 and 1\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "# Main function to create similarity matrices\n",
    "def create_epg_similarity_matrices(df):\n",
    "    # Get unique years, policy areas, and EPGs\n",
    "    years = sorted(df['year'].unique())\n",
    "    policy_areas = sorted(df['policy_area'].unique())\n",
    "    epgs = sorted(df['epg'].unique())\n",
    "    \n",
    "    # Dictionary to store similarity matrices\n",
    "    similarity_matrices = {}\n",
    "    \n",
    "    # Process by year and policy area\n",
    "    for year in years:\n",
    "        year_data = df[df['year'] == year]\n",
    "        \n",
    "        for policy_area in policy_areas:\n",
    "            # Filter data for this year and policy area\n",
    "            pa_data = year_data[year_data['policy_area'] == policy_area]\n",
    "            \n",
    "            if len(pa_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Create empty similarity matrix\n",
    "            sim_matrix = pd.DataFrame(index=epgs, columns=epgs)\n",
    "            \n",
    "            # Calculate vote patterns for each EPG\n",
    "            epg_votes = {}\n",
    "            for epg in epgs:\n",
    "                epg_data = pa_data[pa_data['epg'] == epg]\n",
    "                if len(epg_data) > 0:\n",
    "                    epg_votes[epg] = epg_data['vote'].value_counts()\n",
    "                else:\n",
    "                    epg_votes[epg] = pd.Series()\n",
    "            \n",
    "            # Calculate similarities between all EPG pairs\n",
    "            for epg1, epg2 in combinations(epgs, 2):\n",
    "                if epg1 in epg_votes and epg2 in epg_votes:\n",
    "                    similarity = calculate_similarity(epg_votes[epg1], epg_votes[epg2])\n",
    "                    sim_matrix.loc[epg1, epg2] = similarity\n",
    "                    sim_matrix.loc[epg2, epg1] = similarity  # Matrix is symmetric\n",
    "            \n",
    "            # Set diagonal to 1 (self-similarity)\n",
    "            for epg in epgs:\n",
    "                sim_matrix.loc[epg, epg] = 1.0\n",
    "            \n",
    "            # Store the matrix\n",
    "            matrix_key = (year, policy_area)\n",
    "            similarity_matrices[matrix_key] = sim_matrix.fillna(0)\n",
    "    \n",
    "    return similarity_matrices\n",
    "\n",
    "# Function to plot a similarity matrix\n",
    "def plot_similarity_matrix(matrix, year, policy_area):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1, fmt=\".2f\")\n",
    "    plt.title(f'EPG Voting Similarity - Year: {year}, Policy Area: {policy_area}')\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Main execution code\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    df = pd.read_csv('ep_voting_data_combined.csv')\n",
    "    \n",
    "    # Ensure data types are correct\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    # Create similarity matrices\n",
    "    matrices = create_epg_similarity_matrices(df)\n",
    "    \n",
    "    # Print summary of the matrices created\n",
    "    print(f\"Created {len(matrices)} similarity matrices\")\n",
    "    \n",
    "    # Save each matrix to CSV and create visualization\n",
    "    for (year, policy_area), matrix in matrices.items():\n",
    "        # Save matrix to CSV\n",
    "        filename = f'similarity_matrix_{year}_{policy_area.replace(\" \", \"_\")}.csv'\n",
    "        matrix.to_csv(filename)\n",
    "        print(f\"Saved matrix to {filename}\")\n",
    "        \n",
    "        # Plot and save visualization\n",
    "        fig = plot_similarity_matrix(matrix, year, policy_area)\n",
    "        fig_filename = f'similarity_matrix_{year}_{policy_area.replace(\" \", \"_\")}.png'\n",
    "        fig.savefig(fig_filename)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved visualization to {fig_filename}\")\n",
    "    \n",
    "    # Calculate and print overall average similarity across all years and policy areas\n",
    "    all_similarities = []\n",
    "    for matrix in matrices.values():\n",
    "        # Get all non-diagonal elements\n",
    "        for i in range(len(matrix.index)):\n",
    "            for j in range(i+1, len(matrix.columns)):  # Only upper triangle\n",
    "                all_similarities.append(matrix.iloc[i, j])\n",
    "    \n",
    "    avg_similarity = np.mean(all_similarities)\n",
    "    print(f\"\\nOverall average similarity between EPGs: {avg_similarity:.4f}\")\n",
    "    \n",
    "    # Analyze trends over time (optional)\n",
    "    yearly_avg_similarities = {}\n",
    "    for (year, policy_area), matrix in matrices.items():\n",
    "        if year not in yearly_avg_similarities:\n",
    "            yearly_avg_similarities[year] = []\n",
    "        \n",
    "        # Get all non-diagonal elements for this matrix\n",
    "        similarities = []\n",
    "        for i in range(len(matrix.index)):\n",
    "            for j in range(i+1, len(matrix.columns)):\n",
    "                similarities.append(matrix.iloc[i, j])\n",
    "        \n",
    "        yearly_avg_similarities[year].append(np.mean(similarities))\n",
    "    \n",
    "    # Calculate average similarity by year\n",
    "    yearly_avgs = {year: np.mean(sims) for year, sims in yearly_avg_similarities.items()}\n",
    "    \n",
    "    # Plot trend over time\n",
    "    years = sorted(yearly_avgs.keys())\n",
    "    avgs = [yearly_avgs[year] for year in years]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(years, avgs, marker='o', linestyle='-')\n",
    "    plt.title('Average EPG Voting Similarity Over Time')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Similarity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('epg_similarity_trend.png')\n",
    "    print(\"Saved trend analysis to epg_similarity_trend.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
